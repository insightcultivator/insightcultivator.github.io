---
title: 5차시 1:IBM QC(Single System:Classical Information)
layout: single
classes: wide
categories:
  - Quantum Information
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

# 고전 정보(단일 시스템)

- 출처: [Classical information](https://quantum.cloud.ibm.com/learning/en/courses/basics-of-quantum-information/single-systems/classical-information)

양자 정보와 그 작동 방식을 설명하기 위해, 먼저 **고전** 정보를 개괄적으로 살펴보겠습니다. 양자 정보 강좌에서 왜 그렇게 많은 관심이 고전 정보에 기울여지는지 궁금해할 수도 있지만, 타당한 이유들이 있습니다.

고전이라는 용어는 양자 이론의 발견 이전에 존재했던 물리 이론(예: 뉴턴 역학)에 기반한 개념, 아이디어, 설명을 의미합니다. 정보의 맥락에서 이는 특히 양자 정보와 연결되지 않음을 의미하는 것으로 해석될 수 있습니다.

양자 정보와 고전 정보는 몇 가지 놀라운 방식으로는 다르지만, 그 수학적 설명은 사실 꽤 유사합니다. 고전 정보는 또한 양자 정보를 연구할 때 친숙한 참조점 역할을 하며, 놀랍도록 유용한 비유의 원천이 됩니다. 사람들이 양자 정보에 대해 질문할 때 자연스러운 고전적 비유를 가진 질문을 하는 것이 흔하며, 그러한 질문들은 종종 원래의 양자 정보에 대한 질문에 명확성과 통찰력을 제공할 수 있는 간단한 답을 가집니다. 실제로 고전 정보를 이해하지 못하면 양자 정보를 진정으로 이해할 수 없다고 주장하는 것은 나름 타당하다.

일부 독자들은 이 섹션에서 논의될 내용에 이미 익숙할 수도 있고 그렇지 않을 수도 있지만, 이 논의는 두 가지 독자층 모두를 위한 것입니다. 이 섹션은 양자 정보 입문에 가장 관련 있는 고전 정보의 측면들을 강조하는 것 외에도, 양자 정보 및 계산에서 벡터와 행렬을 설명하는 데 자주 사용되는 **디랙 표기법**을 소개합니다. 디랙 표기법은 양자 정보에만 국한된 것이 아니며, 고전 정보의 맥락뿐만 아니라 벡터와 행렬이 발생하는 다른 많은 설정에서도 똑같이 잘 사용될 수 있습니다.

## 1. 고전 상태 및 확률 벡터

정보를 저장하는 **시스템**이 있다고 가정해 봅시다. 더 구체적으로, 이 시스템은 각 순간에 유한한 수의 **고전 상태** 중 하나에 있을 수 있다고 가정하겠습니다. 여기서 고전 상태라는 용어는 직관적인 용어로, 명확하게 인식하고 설명할 수 있는 구성으로 이해되어야 합니다.

이 강좌에서 시스템은 정보를 저장하는 물리적 장치 또는 매체의 추상화를 의미합니다.

반복적으로 언급될 원형적인 예는 0과 1을 고전 상태로 가지는 시스템인 **비트**입니다. 다른 예로는 고전 상태가 1, 2, 3, 4, 5, 6인 표준 육면체 주사위(상단에 있는 면의 점의 개수로 표시), 고전 상태가 A, C, G, T인 DNA 가닥의 염기, 그리고 고전 상태가 (일반적으로) 높음, 중간, 낮음, 꺼짐인 선풍기 스위치가 있습니다. 수학적 용어로, 시스템의 고전 상태 사양은 실제로 시작점입니다. 우리는 0과 1을 고전 상태로 가지는 시스템을 비트라고 **정의**하며, 다른 고전 상태 세트를 가지는 시스템도 마찬가지입니다.

이 논의를 위해, 고려 중인 시스템에 $\mathsf{X}$라는 이름을 부여하고, $\mathsf{X}$의 고전 상태 집합을 나타내기 위해 $\Sigma$ 기호를 사용하겠습니다. $\Sigma$가 유한하다는 가정이 이미 언급되었지만, 우리는 자연스럽게 $\Sigma$가 **비어 있지 않다**고 가정합니다. 물리적 시스템이 상태를 전혀 가질 수 없다는 것은 무의미하기 때문입니다. 그리고 무한히 많은 고전 상태를 가지는 물리적 시스템을 고려하는 것이 의미가 있긴 하지만, 이 과정과 관련이 없고 확실히 흥미롭긴 하지만 이 가능성은 무시하겠습니다. 이러한 이유로, 그리고 편의와 간결함을 위해, 우리는 앞으로 **고전 상태 집합**이라는 용어를 모든 유한하고 비어 있지 않은 집합을 의미하는 것으로 사용하겠습니다.

몇 가지 예는 다음과 같습니다.
1.  $\mathsf{X}$가 비트라면, $\Sigma = \{0,1\}$입니다. 이 집합을 **이진 알파벳**이라고 부릅니다.
2.  $\mathsf{X}$가 육면체 주사위라면, $\Sigma = \{1,2,3,4,5,6\}$입니다.
3.  $\mathsf{X}$가 선풍기 스위치라면, $\Sigma = \{\mathrm{high}, \mathrm{medium}, \mathrm{low}, \mathrm{off}\}$입니다.

$\mathsf{X}$를 정보의 운반체로 생각할 때, $\mathsf{X}$의 다양한 고전 상태는 특정 의미를 부여받아 다른 결과나 영향을 초래할 수 있습니다. 이러한 경우, $\mathsf{X}$가 단순히 가능한 고전 상태 중 하나에 있다고 설명하는 것으로 충분할 수 있습니다. 예를 들어, $\mathsf{X}$가 선풍기 스위치라면, 우리는 그것이 확실히 '강'으로 설정되어 있다는 것을 알게 되어, '중간'으로 전환할 수도 있습니다.

그러나 정보 처리에서는 종종 우리의 지식이 불확실합니다. 시스템 $\mathsf{X}$의 고전 상태에 대한 우리의 지식을 나타내는 한 가지 방법은 그 가능한 다양한 고전 상태에 **확률**을 연관시키는 것으로, 이를 **확률적 상태**라고 부릅니다. 예를 들어, $\mathsf{X}$가 비트라고 가정해 봅시다. $\mathsf{X}$에 과거에 어떤 일이 일어났는지에 대해 우리가 아는 바나 예상하는 바에 따라, 우리는 $\mathsf{X}$가 고전 상태 0에 있을 확률이 $3/4$이고 상태 1에 있을 확률이 $1/4$이라고 믿을 수 있습니다. 우리는 이러한 믿음을 다음과 같이 표현할 수 있습니다.


$
\operatorname{Pr}(\mathsf{X}=0) = \frac{3}{4}
\quad\text{and}\quad
\operatorname{Pr}(\mathsf{X}=1) = \frac{1}{4}.
$

이 확률적 상태를 표현하는 더 간결한 방법은 열 벡터를 사용하는 것입니다.
$$\begin{pmatrix}
  \frac{3}{4} \\
  \frac{1}{4}\end{pmatrix}
  $$

비트가 0일 확률은 벡터의 맨 위에, 비트가 1일 확률은 맨 아래에 놓입니다. 이는 $\{0,1\}$ 집합을 순서대로 정렬하는 관습적인 방식이기 때문입니다. 

일반적으로, 우리는 어떤 고전 상태 집합을 가지는 시스템의 확률적 상태를 같은 방식으로 확률 벡터로 표현할 수 있습니다. 확률들은 우리가 선택하는 어떤 방식으로든 순서가 정해질 수 있지만, 자연스럽거나 기본 순서가 있는 것이 일반적입니다. 정확히 말하면, 우리는 두 가지 속성을 만족하는 열 벡터를 통해 어떤 확률적 상태도 표현할 수 있습니다.

1.  벡터의 모든 엔트리는 **음이 아닌 실수**입니다.
2.  엔트리들의 합은 1과 같습니다.

반대로, 이 두 가지 속성을 만족하는 모든 열 벡터는 확률적 상태의 표현으로 간주될 수 있습니다. 앞으로 우리는 이러한 형태의 벡터를 **확률 벡터**라고 부를 것입니다. 이 표기법의 간결성과 함께, 확률적 상태를 열 벡터로 식별하는 것은 확률적 상태에 대한 연산이 행렬-벡터 곱셈을 통해 표현된다는 장점을 가집니다. 이는 곧 논의될 것입니다.

## 2. 확률적 상태 측정

다음으로, 시스템이 확률적 상태에 있을 때 **측정**하면 어떻게 되는지 고려해 봅시다. 이 맥락에서, 시스템을 측정한다는 것은 단순히 시스템을 보고 그것이 어떤 고전 상태에 있는지 명확하게 인식하는 것을 의미합니다. 직관적으로 말하면, 우리는 시스템의 확률적 상태를 "볼" 수 없습니다. 우리가 그것을 볼 때, 우리는 가능한 고전 상태 중 하나만을 볼 뿐입니다. 

시스템을 측정함으로써, 우리는 그것에 대한 우리의 지식을 변경할 수도 있으며, 따라서 우리가 그것과 연관시키는 확률적 상태가 변경될 수 있습니다. 즉, $\mathsf{X}$가 고전 상태 $a \in \Sigma$에 있다는 것을 인식하면, $\mathsf{X}$의 상태에 대한 우리의 지식을 나타내는 새로운 확률 벡터는 $a$에 해당하는 엔트리에 1을 가지고 다른 모든 엔트리에는 0을 가지는 벡터가 됩니다. 이 벡터는 $\mathsf{X}$가 확실히 고전 상태 $a$에 있음을 나타냅니다 (우리가 방금 그것을 인식했기 때문에 압니다). 그리고 우리는 이 벡터를 $\|a\rangle$로 나타내며, 이는 곧 설명될 이유로 "켓 $a$"라고 읽습니다. 이러한 종류의 벡터는 **표준 기저** 벡터라고도 불립니다.

예를 들어, 우리가 염두에 둔 시스템이 비트라고 가정하면, 표준 기저 벡터는 다음 수식으로 주어집니다. 


  $\vert 0\rangle$ = $$\begin{pmatrix}1\\ 0\end{pmatrix}
  \quad\text{and}\quad
  \vert 1\rangle = \begin{pmatrix}0\\ 1\end{pmatrix}$$.


임의의 2차원 열 벡터는 이 두 벡터의 선형 결합으로 표현될 수 있음을 주목하십시오. 예를 들어, 

$$
\begin{pmatrix}
  \frac{3}{4}\\[2mm]
  \frac{1}{4}
\end{pmatrix}$$
= $\frac{3}{4}\,\vert 0\rangle + \frac{1}{4}\,\vert 1\rangle$.


이 사실은 어떤 고전 상태 집합에도 자연스럽게 일반화됩니다. 즉, 어떤 열 벡터도 표준 기저 상태의 선형 결합으로 작성될 수 있습니다. 우리는 종종 벡터를 정확히 이런 방식으로 표현합니다.

측정 시 확률적 상태의 변화로 돌아가서, 우리는 우리의 일상 경험과의 다음 연결을 주목할 수 있습니다. 공정한 동전을 던진 후, 보기 전에 동전을 덮어놓았다고 가정해 봅시다. 그러면 우리는 그 확률적 상태가 다음과 같다고 말할 것입니다. 


$$
\begin{pmatrix}
  \frac{1}{2}\\[2mm]
  \frac{1}{2}
\end{pmatrix}$$
= $\frac{1}{2}\,\vert\text{heads}\rangle + \frac{1}{2}\,\vert\text{tails}\rangle$.


여기서 우리 동전의 고전 상태 집합은 $\{\text{앞면}, \text{뒷면}\}$입니다. 우리는 이 상태들을 앞면을 먼저, 뒷면을 나중에 정렬하기로 선택할 것입니다.


$\vert\text{heads}\rangle$ = $$\begin{pmatrix}1\\ 0\end{pmatrix}
\quad\text{and}\quad
\vert\text{tails}\rangle = \begin{pmatrix}0\\[1mm] 1\end{pmatrix}
$$

우리가 동전을 드러내고 본다면, 앞면 또는 뒷면 중 하나의 고전 상태를 볼 것입니다. 결과가 뒷면이었다고 가정하면, 우리는 당연히 동전의 확률적 상태에 대한 우리의 설명을 $\|\text{뒷면}\rangle$이 되도록 업데이트할 것입니다. 
물론, 우리가 동전을 다시 덮고, 다시 드러내어 본다면, 고전 상태는 여전히 뒷면일 것이고, 이는 확률적 상태가 벡터 $\|\text{뒷면}\rangle$로 설명되는 것과 일치합니다.

이것은 사소하게 보일 수 있으며, 어떤 면에서는 그렇습니다. 그러나 양자 시스템은 완전히 유사한 방식으로 행동하지만, 그 측정 특성은 종종 이상하거나 특이하다고 간주됩니다. 고전 시스템의 유사한 특성을 확립함으로써, 양자 정보의 작동 방식이 덜 특이하게 보일 수 있습니다. 

확률적 상태의 측정에 관한 마지막 언급은 다음과 같습니다. 확률적 상태는 지식이나 믿음을 설명하며, 반드시 실제적인 것을 설명하는 것은 아니며, 측정은 단지 우리의 지식을 변경할 뿐 시스템 자체를 변경하지 않습니다. 예를 들어, 동전을 던진 후 보지 않은 상태의 동전은 앞면 또는 뒷면 중 하나이지만, 우리가 볼 때까지는 어떤 것인지 알 수 없습니다. 고전 상태가 뒷면인 것을 보았다고 가정하면, 우리는 당연히 우리의 지식을 설명하는 벡터를 $\|\text{뒷면}\rangle$으로 업데이트할 것이지만, 동전이 드러났을 때 그것을 보지 못한 다른 사람에게는 확률적 상태가 변경되지 않은 채로 남아 있을 것입니다. 이것은 걱정할 이유가 없습니다. 다른 개인은 특정 시스템에 대해 다른 지식이나 믿음을 가질 수 있으며, 따라서 다른 확률 벡터로 시스템을 설명할 수 있습니다.

## 3. 고전 연산

고전 정보에 대한 이 간략한 요약의 마지막 부분에서는 고전 시스템에서 수행할 수 있는 연산의 종류를 고려할 것입니다.

### 3.1 결정론적 연산

첫째, **결정론적** 연산이 있습니다. 이는 각 고전 상태 $a \in \Sigma$가 $f:\Sigma \rightarrow \Sigma$ 형태의 어떤 함수 $f$에 의해 $f(a)$로 변환되는 연산입니다.

연산은 입력에 의해 결과가 완전히 결정되고 우연이나 불확실성 요소가 없다면 결정론적입니다.


예를 들어, $\Sigma = \{0,1\}$이라면, 이러한 형태의 함수는 $f_1, f_2, f_3, f_4$ 네 가지가 있으며, 다음과 같이 값의 표로 표현될 수 있습니다.

$$
\begin{array}{c|c}
  a & f_1(a)\\
  \hline
  0 & 0\\
  1 & 0
\end{array}$$
$\qquad$
$$
\begin{array}{c|c}
  a & f_2(a)\\
  \hline
  0 & 0\\
  1 & 1
\end{array}$$
$\qquad$
$$
\begin{array}{c|c}
  a & f_3(a)\\
  \hline
  0 & 1\\
  1 & 0
\end{array}$$
$\qquad$
$$
\begin{array}{c|c}
  a & f_4(a)\\
  \hline
  0 & 1\\
  1 & 1
\end{array}
$$

이 함수들 중 첫 번째와 마지막은 **상수** 함수입니다. 즉, 모든 $a \in \Sigma$에 대해 $f_1(a) = 0$이고 $f_4(a) = 1$입니다. 가운데 두 함수는 상수가 아니며, **균형** 함수입니다. 가능한 입력에 대해 탐색할 때 두 출력 값 각각이 같은 횟수(이 경우 한 번)로 나타납니다. 함수 $f_2$는 **항등 함수**입니다. 즉, 모든 $a \in \Sigma$에 대해 $f_2(a) = a$입니다. 그리고 $f_3$는 $f_3(0) = 1$이고 $f_3(1) = 0$인 함수이며, 이는 NOT 함수로 더 잘 알려져 있습니다.

항등 함수는 입력을 변경하지 않고 반환합니다.

확률적 상태에 대한 결정론적 연산의 작용은 행렬-벡터 곱셈으로 표현될 수 있습니다. 구체적으로, 주어진 함수 $f:\Sigma \rightarrow \Sigma$를 나타내는 행렬 $M$은 모든 $a \in \Sigma$에 대해 다음을 만족하는 행렬입니다. 

$
M \vert a \rangle = \vert f(a)\rangle
$

이러한 행렬은 항상 존재하며 이 요구 사항에 의해 고유하게 결정됩니다. 결정론적 연산을 나타내는 행렬은 항상 각 열에 정확히 하나의 1을 가지며, 다른 모든 엔트리는 0입니다.

예를 들어, 위에서 언급한 함수 $f_1, \ldots, f_4$에 해당하는 행렬 $M_1, \ldots, M_4$는 다음과 같습니다. 


  $M_1 =$
  $$
  \begin{pmatrix}
    1 & 1\\
    0 & 0
  \end{pmatrix}$$,
  $\hspace{4mm}
  M_2 =$
  $$
  \begin{pmatrix}
    1 & 0\\
    0 & 1
  \end{pmatrix}$$,
  $\hspace{4mm}
  M_3 =$
  $$\begin{pmatrix}
    0 & 1\\
    1 & 0
  \end{pmatrix}$$,
  $\hspace{4mm}
  M_4 = $
 $$ \begin{pmatrix}
    0 & 0\\
    1 & 1
  \end{pmatrix}$$


첫 번째 행렬이 올바른지 보여주는 간단한 확인입니다. 다른 세 행렬도 유사하게 확인할 수 있습니다.

$
M_1 \vert 0\rangle $ =
$$
\begin{pmatrix}
  1 & 1\\
  0 & 0
\end{pmatrix}
\begin{pmatrix}
  1\\
  0
\end{pmatrix}
= \begin{pmatrix}
  1\\
  0
\end{pmatrix}$$
= $ \vert 0\rangle = \vert f_1(0)\rangle $


$ M_1 \vert 1\rangle = $
$$ \begin{pmatrix}
  1 & 1\\
  0 & 0
\end{pmatrix}
\begin{pmatrix}
  0\\
  1
\end{pmatrix}
= \begin{pmatrix}
  1\\
  0
\end{pmatrix}$$
$ = \vert 0\rangle = \vert f_1(1)\rangle$

이러한 형태의 행렬 및 다른 형태의 행렬을 표현하는 편리한 방법은 이전에 논의된 열 벡터와 유사한 행 벡터 표기법을 활용합니다. 우리는 각 $a \in \Sigma$에 대해 $a$에 해당하는 엔트리에 1을 가지고 다른 모든 엔트리에 0을 가지는 **행** 벡터를 $\langle a\|$로 나타냅니다. 이 벡터는 "브라 $a$"라고 읽습니다.

예를 들어, $\Sigma = \{0,1\}$이라면, 

$
  \langle 0 \vert$ = $$ \begin{pmatrix}
    1 & 0
  \end{pmatrix}$$
  $\quad\text{and}\quad
  \langle 1 \vert $ = $$\begin{pmatrix}
    0 & 1
  \end{pmatrix}.
$$

어떤 고전 상태 집합 $\Sigma$에 대해서도, 우리는 행 벡터와 열 벡터를 행렬로 볼 수 있으며, 행렬 곱셈 $\vert b\rangle \langle a\vert$를 수행할 수 있습니다. 우리는 쌍 $(b,a)$에 해당하는 엔트리(즉, 엔트리의 행은 고전 상태 $b$에 해당하고 열은 고전 상태 $a$에 해당)에 1을 가지고 다른 모든 엔트리에 0을 가지는 정방 행렬을 얻습니다. 예를 들어,

$
  \vert 0 \rangle \langle 1 \vert = $
  $$ \begin{pmatrix}
  1\\
  0
  \end{pmatrix}
  \begin{pmatrix}
  0 & 1
  \end{pmatrix} =
  \begin{pmatrix}
    0 & 1 \\
    0 & 0
  \end{pmatrix}$$.


이 표기법을 사용하여, 우리는 주어진 함수 $f:\Sigma\rightarrow\Sigma$에 해당하는 행렬 $M$을 다음으로 표현할 수 있습니다.

\[
  M = \sum_{a\in\Sigma} \vert f(a) \rangle \langle a \vert.
\]

예를 들어, 위에서 $\Sigma = \{0,1\}$인 함수 $f_4$를 고려해 봅시다. 우리는 행렬을 얻습니다.

$
M_4 = \vert f_4(0) \rangle \langle 0 \vert + \vert f_4(1) \rangle \langle 1 \vert
= \vert 1\rangle \langle 0\vert + \vert 1\rangle \langle 1\vert$
$$ = \begin{pmatrix}
0 & 0\\
1 & 0
\end{pmatrix} +
\begin{pmatrix}
0 & 0\\
0 & 1
\end{pmatrix}
= \begin{pmatrix}
0 & 0\\
1 & 1
\end{pmatrix}.
$$

이것이 작동하는 이유는 다음과 같습니다. 벡터를 다시 행렬로 생각하고, 이번에는 곱셈 $\langle a \vert \vert b \rangle$를 고려하면, 우리는 스칼라(즉, 숫자)로 생각할 수 있는 $1 \times 1$ 행렬을 얻습니다. 간결함을 위해, 우리는 이 곱을 $\langle a \vert \vert b \rangle$ 대신 $\langle a \vert b\rangle$로 씁니다. 이 곱은 다음 간단한 공식을 만족합니다.



  $\langle a \vert b \rangle$
  = $$ \begin{cases}
    1 & a = b\\[1mm]
    0 & a \neq b.
  \end{cases}
$$

이 관찰과 행렬 곱셈이 결합적이고 선형적이라는 사실을 함께 사용하여, 우리는 각 $b \in \Sigma$에 대해 다음을 얻으며, 

\[
  M \vert b \rangle =
  \Biggl(
  \sum_{a\in\Sigma} \vert f(a) \rangle \langle a \vert
  \Biggr)
  \vert b\rangle
  = \sum_{a\in\Sigma} \vert f(a) \rangle \langle a \vert b \rangle
  = \vert f(b)\rangle,
\]

이는 행렬 $M$에 대해 우리가 정확히 요구하는 바입니다. 나중에 더 자세히 논의되겠지만, $\langle a \vert b \rangle$는 벡터 $\vert a\rangle$와 $\vert b\rangle$ 사이의 **내적**으로도 볼 수 있습니다. 내적은 양자 정보에서 매우 중요하지만, 필요할 때까지는 논의를 미루겠습니다.

이 시점에서 "브라"와 "켓"이라는 이름이 명백할 것입니다. "브라" $\langle a\vert$를 "켓" $\vert b\rangle$와 함께 놓으면 "브라켓" $\langle a \vert b\rangle$이 됩니다. 이 표기법과 용어는 **폴 디랙**에 의해 고안되었으며, 이 때문에 **디랙 표기법**으로 알려져 있습니다. 

### 3.2 확률적 연산 및 확률 행렬
결정론적 연산 외에도 **확률적 연산**이 있습니다.

예를 들어, 비트에 대한 다음 연산을 고려해 봅시다. 비트의 고전 상태가 0이면 그대로 두고, 비트의 고전 상태가 1이면 뒤집어서 $1/2$ 확률로 0이 되고 $1/2$ 확률로 1이 됩니다. 이 연산은 행렬로 표현됩니다. 

$$
  \begin{pmatrix}
    1 & \frac{1}{2}\\
    0 & \frac{1}{2}
  \end{pmatrix}$$.


이 행렬이 두 표준 기저 벡터를 곱하여 올바르게 작동하는지 확인할 수 있습니다. 

고전 상태 집합의 임의의 선택에 대해, 우리는 모든 확률적 연산의 집합을 **확률** 행렬로 표현되는 것으로 수학적으로 설명할 수 있습니다. 확률 행렬은 다음 두 가지 속성을 만족하는 행렬입니다.'확률적'은 대략 '무작위적'을 의미합니다. 확률 행렬은 무작위 과정을 나타냅니다.

1.  모든 엔트리는 음이 아닌 실수입니다.
2.  모든 열의 엔트리 합은 1과 같습니다.

동등하게, 확률 행렬은 모든 열이 확률 벡터를 형성하는 행렬입니다. 

우리는 확률적 연산을 직관적인 수준에서, 위의 예시처럼 연산 중에 무작위성이 어떤 식으로든 사용되거나 도입될 수 있는 것으로 생각할 수 있습니다. 확률적 연산의 확률 행렬 설명에 관해서는, 각 열은 해당 열에 해당하는 고전 상태 입력이 주어졌을 때 생성되는 확률적 상태의 벡터 표현으로 볼 수 있습니다.

우리는 또한 확률 행렬이 항상 확률 벡터를 확률 벡터로 매핑하는 행렬이며, 확률 벡터를 항상 확률 벡터로 매핑하는 모든 행렬은 확률 행렬이어야 한다고 생각할 수 있습니다.

마지막으로, 확률적 연산을 생각하는 또 다른 방법은 그것이 결정론적 연산의 무작위 선택이라는 것입니다. 예를 들어, 위의 예시에서 연산을 항등 함수 또는 상수 0 함수를 각각 $1/2$ 확률로 적용하는 것으로 생각할 수 있습니다. 이는 방정식 다음과 일치합니다. 


$$
  \begin{pmatrix}
    1 & \frac{1}{2} \\
    0 & \frac{1}{2}
  \end{pmatrix}$$
  = $\frac{1}{2}$
  $$ \begin{pmatrix}
    1 & 0 \\
    0 & 1
  \end{pmatrix}$$
  $ + \frac{1}{2}$
  $$
  \begin{pmatrix}
    1 & 1 \\
    0 & 0
  \end{pmatrix}$$.


이러한 표현은 고전 상태 집합의 임의의 선택과 해당 고전 상태 집합으로 행과 열이 식별되는 모든 확률 행렬에 대해 항상 가능합니다.

### 3.3 확률적 연산의 합성
$\mathsf{X}$가 고전 상태 집합 $\Sigma$를 가지는 시스템이고, $M_1, \ldots, M_n$이 시스템 $\mathsf{X}$에 대한 확률적 연산을 나타내는 확률 행렬이라고 가정해 봅시다.

첫 번째 연산 $M_1$이 확률 벡터 $u$로 표현되는 확률적 상태에 적용되면, 결과 확률적 상태는 벡터 $M_1 u$로 표현됩니다. 그런 다음 이 새로운 확률 벡터에 두 번째 확률적 연산 $M_2$를 적용하면, 우리는 확률 벡터를 얻습니다. 

$
  M_2 (M_1 u) = (M_2 M_1) u.
$

이 등식은 행렬 곱셈(행렬-벡터 곱셈을 특수한 경우로 포함)이 **결합적** 연산이라는 사실에서 비롯됩니다. 따라서 첫 번째 및 두 번째 확률적 연산을 **합성**하여 얻은 확률적 연산(즉, 먼저 $M_1$을 적용한 다음 $M_2$를 적용)은 행렬 $M_2 M_1$로 표현되며, 이는 필연적으로 확률적입니다.

연산은 괄호의 위치를 이동해도 같은 결과가 나오면 결합적입니다.
합성은 한 함수나 연산을 다른 함수나 연산 다음에 적용하는 것을 의미합니다.

더 일반적으로, 행렬 $M_1, \ldots, M_n$으로 표현되는 확률적 연산들을 이 순서대로 합성하는 것은 (즉, $M_1$이 먼저 적용되고, $M_2$가 두 번째로 적용되며, $M_n$이 마지막으로 적용되는 순서) 행렬 곱으로 표현됩니다. 


$
  M_n \,\cdots\, M_1.
$

여기서 순서가 중요하다는 점에 유의하십시오. 행렬 곱셈은 결합적이지만, **교환적** 연산은 아닙니다. 예를 들어, 



  $M_1$ =
  $$ \begin{pmatrix}
    1 & 1 \\
    0 & 0
  \end{pmatrix}$$
  $\quad\text{and}\quad$
  $M_2$ =
  $$\begin{pmatrix}
    0 & 1 \\
    1 & 0
  \end{pmatrix},
$$

then


  $M_2 M_1$ =
  $$\begin{pmatrix}
    0 & 0 \\
    1 & 1
  \end{pmatrix}$$
  $ \quad\text{and}\quad$
  $M_1 M_2$ =
  $$\begin{pmatrix}
    1 & 1\\[1mm]
    0 & 0
  \end{pmatrix}.
$$


즉, 확률적 연산이 합성되는 순서가 중요하며, 연산이 적용되는 순서를 변경하면 결과 연산이 변경될 수 있습니다.

