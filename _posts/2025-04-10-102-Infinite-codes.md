---
title: 28차시 2:Infinite Codes
layout: single
classes: wide
categories:
  - ML
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 7. 머신러닝 초보자들이 흔히 저지르는 실수 & 해결책
- 출처: [All Machine Learning Beginner Mistakes explained in 17 Min](https://www.youtube.com/watch?v=oMc9StPVzOU)


### 7.1  **데이터 준비:** 모델 성능의 초석을 다지는 단계
* **데이터 미정리:** 모델 학습의 기반을 흔드는 문제점
    *  결측값(Missing Value), 이상치(Outlier), 중복된 항목(Duplicate Entry), 일관성 없는 텍스트 필드(Inconsistent Text Field) 등은 데이터의 품질을 저하시키고 모델의 예측 성능에 부정적인 영향
    * **해결책:** 
        - 데이터 클리닝(Data Cleaning) 작업에 충분한 시간을 투자하여 결측치 처리(Imputation), 이상치 탐지 및 제거/변환, 중복 항목 제거, 텍스트 데이터 정규화 등의 과정을 수행해야 합니다.
* **정규화/표준화 누락:** 특성 스케일 불일치로 인한 학습 방해
    *  서로 다른 단위를 갖거나 값의 범위가 크게 차이나는 특성(Feature)들은 모델 학습 시 특정 특성에 과도한 영향을 미치거나 학습 속도를 저하시키는 원인이 됩니다.
    * **해결책:** 
        - 특성 스케일링(Feature Scaling) 기법 적용하여 모든 특성들이 유사한 범위의 값을 갖도록 변환 
        - 일반적인 방법으로는 데이터를 0과 1 사이의 범위로 조정하는 정규화(Normalization, Min-Max Scaling) 또는 평균을 0, 분산을 1로 만드는 표준화(Standardization, Z-score Scaling)
* **Train/Test 분리 전 전처리:** 정보 누출(Data Leakage)의 위험
    *  훈련 데이터셋(Train Set)과 테스트 데이터셋(Test Set)을 나누기 전에 전체 데이터셋에 대해 전처리(Preprocessing)를 수행하면 테스트 데이터의 정보가 훈련 과정에 간접적으로 영향을 미쳐 모델의 일반화 성능을 제대로 평가할 수 없게 됩니다.
    * **해결책:** 
        - 데이터를 먼저 훈련 세트와 테스트 세트로 분리한 후, 각 세트에 대해 독립적으로 전처리 과정을 적용해야 합니다.
* **클래스 불균형:** 특정 클래스 편향으로 인한 성능 저하
    *  분류(Classification) 문제에서 특정 클래스의 데이터 수가 다른 클래스에 비해 현저히 많거나 적으면 모델이 다수 클래스에 편향되어 소수 클래스를 제대로 학습하지 못할 수 있습니다.
    * **해결책:** 
        - 데이터 불균형을 해소하기 위해 소수 클래스의 데이터를 늘리는 오버샘플링(Oversampling), 다수 클래스의 데이터를 줄이는 언더샘플링(Undersampling), 또는 SMOTE(Synthetic Minority Over-sampling Technique)와 같은 합성 데이터 생성 기법을 사용할 수 있습니다. 
        - 또한, 정확도(Accuracy) 외에도 정밀도(Precision), 재현율(Recall), F1 점수(F1 score) 등 다양한 평가 지표를 함께 고려해야 합니다.
* **결측치 처리 미흡:** 단순 대체의 함정
    *  결측치를 단순히 무시하거나 전체 데이터의 평균 또는 0으로 채우는 방식은 데이터의 실제 분포를 왜곡하거나 중요한 정보를 손실시킬 수 있습니다.
    * **해결책:** 
        - 결측치가 발생하는 이유를 면밀히 분석하고, 데이터의 특성에 따라 적절한 대체 방법(평균, 중앙값, KNN(K-Nearest Neighbors)을 이용한 예측, 회귀 모델을 이용한 예측 등)을 선택해야 
        - 만약 결측 자체가 의미 있는 정보라면, 결측 여부를 나타내는 새로운 특성(Feature)으로 인코딩하는 것을 고려할 수 있습니다.
* **잘못된 Feature Encoding:** 범주형 데이터의 순서 왜곡
    *  순서가 없는 범주형(Categorical) 변수에 순서가 있는 것처럼 Label Encoding을 적용하면 모델이 잘못된 순서 관계를 학습할 수 있습니다.
    * **해결책:** 
        - 명목형(Nominal) 변수에는 One-Hot Encoding을 적용하여 각 범주를 독립적인 이진 특성으로 변환하고, 순서형(Ordinal) 변수에는 Label Encoding을 유지하거나 Embedding 등 고려
        - 중요한 것은 훈련 데이터에 적용한 인코딩 방식을 테스트 데이터에도 동일하게 적용해야 합니다.
* **데이터 섞기 미흡:** 인위적인 패턴 학습 방지
    *  데이터가 특정 순서로 정렬되어 있는 경우(예: 시간 순서) 훈련 과정에서 모델이 실제로는 존재하지 않는 인위적인 패턴을 학습할 가능성이 있습니다.
    * **해결책:** 
        - 모델 학습 전에 훈련 데이터를 무작위로 섞어(Shuffle) 모델이 데이터의 순서에 의존하지 않고 일반적인 패턴을 학습하도록 해야 합니다.

### 7.2  **모델 평가:** 모델 성능을 객관적으로 측정하는 과정

* **잘못된 평가 지표 선택:** 문제 유형과 목표 불일치
    *  정확도는 전체 예측 중 정답 비율을 나타내는 간단한 지표이지만, 클래스 불균형 문제에서는 모델의 실제 성능을 과대평가할 수 있습니다.
    * **해결책:** 
        - 풀고자 하는 문제의 유형과 비즈니스 목표에 부합하는 적절한 평가 지표를 선택해야 합니다. 
        - 분류 문제에서는 정밀도(Precision), 재현율(Recall), F1 점수(F1 score), 평균 정밀도(Average Precision, AP), 정규화된 할인 누적 이득(Normalized Discounted Cumulative Gain, NDCG) 등을 고려할 수 있으며, 
        - 회귀 문제에서는 평균 제곱 오차(Mean Squared Error, MSE), 평균 절대 오차(Mean Absolute Error, MAE) 등을 사용할 수 있습니다.
* **과적합/과소적합:** 모델의 일반화 능력 저하
    *  과적합(Overfitting)은 모델이 훈련 데이터에는 지나치게 잘 작동하지만 새로운 데이터에는 제대로 예측하지 못하는 현상이며, 과소적합(Underfitting)은 모델이 훈련 데이터조차 제대로 학습하지 못하는 현상입니다.
    * **해결책:** 
        - 과적합을 방지하기 위해 교차 검증(Cross-Validation), 규제화(Regularization, L1/L2 규제), Early Stopping 등의 기법을 적용하고, 
        - 훈련 데이터와 검증 데이터에 대한 성능 변화 추이를 나타내는 학습 곡선(Learning Curve)을 분석하여 과적합 또는 과소적합 여부를 판단해야 합니다.
* **교차 검증 미흡:** 일반화 성능 평가의 불확실성 증대
    *  단일의 훈련-테스트 데이터 분할은 데이터 분할 방식에 따라 모델 성능 평가 결과가 크게 달라질 수 있으며, 모델의 일반화 성능을 신뢰하기 어렵게 만듭니다.
    * **해결책:** 
        - K-Fold 교차 검증을 사용하여 데이터를 여러 개의 폴드로 나누고, 각 폴드를 번갈아 가며 검증 세트로 사용하여 모델을 평가합니다. 
        - 분류 문제에서는 각 폴드 내 클래스 비율을 유지하는 Stratified K-Fold를 고려하고, 
        - 시계열 데이터의 경우에는 시간 기반 분할(Time-Based Splitting) 방식을 적용해야 합니다.
* **Train/Test 오염:** 모델 평가의 신뢰성 훼손
    *  테스트 데이터가 직간접적으로 훈련 과정에 사용되는 경우(예: 하이퍼파라미터 튜닝 시 테스트 데이터 성능을 참고하는 경우, Feature Selection 시 테스트 데이터의 통계치를 사용하는 경우) 모델이 테스트 데이터에 과적합되어 실제 새로운 데이터에 대한 성능을 제대로 예측할 수 없게 됩니다.
    * **해결책:** 
        - 테스트 세트를 훈련 전에 완전히 분리하고, 하이퍼파라미터 튜닝이나 특성 선택(Feature Selection)과 같은 모델 개발 과정에서 테스트 데이터를 절대 사용해서는 안 됩니다.
* **잘못된 손실 함수:** 학습 목표와 평가 기준 불일치
    *  문제의 유형에 적합하지 않은 손실 함수(Loss Function)를 사용하면 모델이 원하는 방향으로 학습되지 않아 성능 저하를 초래할 수 있습니다.
    * **해결책:** 
        - 분류 문제에는 Cross Entropy, 
        - 회귀 문제에는 MSE(Mean Squared Error), MAE(Mean Absolute Error) 등 해결하려는 문제의 특성에 맞는 적절한 손실 함수를 선택해야 합니다.
* **유효성 검사 전략 부실:** 모델 성능 평가의 객관성 부족
    *  부적절한 교차 검증 방법의 사용, 데이터 누출(Data Leakage) 발생 등은 모델의 실제 성능을 정확하게 평가하는 것을 어렵게 만듭니다.
    * **해결책:** 
        - 문제 유형에 맞는 교차 검증 방법을 신중하게 선택하고(예: 시계열 데이터의 경우 시간 기반 분할, 사용자 기반 추천 시스템의 경우 사용자 기반 분할 등), 실제 서비스 환경과 유사한 방식으로 데이터를 분할하여 모델을 평가해야 합니다.

### 7.3  **학습 과정:** 모델 최적화를 위한 중요한 단계

* **학습률(Learning Rate) 오류:** 최적점 수렴 실패 또는 속도 저하
    *  학습률이 너무 크면 모델의 가중치가 최적점을 지나쳐 발산(Divergence)할 수 있고, 너무 작으면 학습 속도가 매우 느려져 최적점에 도달하지 못할 수 있습니다.
    * **해결책:** 
        - 적절한 초기 학습률(일반적으로 0.01, 0.001 등)을 설정하고, 학습이 진행됨에 따라 학습률을 점진적으로 줄이는 학습률 스케줄링(Learning Rate Scheduling) 기법을 사용
* **하이퍼파라미터 튜닝 부족:** 최적 모델 구성의 어려움
    *  배치 크기(Batch Size), 네트워크 구조(Network Architecture) 등 모델의 성능에 큰 영향을 미치는 하이퍼파라미터(Hyperparameter)를 임의로 설정하는 것은 최적의 모델 성능을 얻기 어렵게 만듦
    * **해결책:** 
        - Grid Search, Random Search, Bayesian Optimization 등의 하이퍼파라미터 탐색 기법을 활용하여 검증 데이터셋(Validation Set)에 대한 성능을 최적화하는 하이퍼파라미터 조합을 찾아야 합니다. 이때, 검증 데이터셋에 과적합되지 않도록 주의해야 합니다.

### 7.4  **기타:** 간과하기 쉬운 중요한 요소들

* **복잡한 모델 조기 사용:** 단순 모델부터 시작하는 것이 중요
    *  처음부터 복잡한 모델을 사용하는 것은 문제 해결에 불필요한 복잡성을 더하고, 모델 해석을 어렵게 만들며, 과적합의 위험을 높일 수 있습니다.
    * **해결책:** 
        - 로지스틱 회귀(Logistic Regression), 결정 트리(Decision Tree)와 같은 비교적 단순한 모델부터 시작하여 성능 향상 여부를 확인하고, 필요에 따라 점진적으로 모델의 복잡도를 높여나가기
* **기본 모델(Baseline Model) 이해 부족:** 성능 비교 기준의 부재
    *  개발한 복잡한 모델의 성능이 단순히 평균값을 예측하거나 최빈값을 예측하는 기본적인 모델보다 얼마나 더 나은지 판단할 기준이 없다면 모델의 실제 효용성을 평가하기 어렵습니다.
    * **해결책:** 
        - 문제에 대한 간단한 규칙 기반 모델이나 통계적인 기본 모델(예: 평균값 예측, 최빈값 예측)을 먼저 구축하여 복잡한 모델의 성능 향상 정도를 객관적으로 평가할 수 있는 기준을 마련해야 합니다.
* **도메인 지식 부족:** 데이터 이해와 모델 해석의 어려움
    *  데이터의 기술적인 패턴만으로는 문제의 본질을 이해하고 의미 있는 모델을 구축하기 어렵습니다. 비즈니스 맥락(Business Context)에 대한 이해가 부족하면 중요한 특성을 놓치거나 데이터 품질 문제를 간과할 수 있으며, 모델 예측의 현실성을 판단하기 어려울 수 있습니다.
    * **해결책:** 
        - 해당 분야의 전문가와 적극적으로 협력하여 데이터의 의미를 파악하고, 중요한 특성을 식별하며, 데이터 품질 문제를 발견하고, 모델 예측의 현실성을 검증하는 과정을 거쳐야 합니다.
* **모델 가정 무시:** 성능 저하의 원인
    *  선형 회귀(Linear Regression)의 선형성(Linearity), Naive Bayes 분류기의 특성 독립성(Feature Independence) 등 각 모델은 특정한 가정을 기반으로 작동합니다. 이러한 가정을 위배하는 데이터를 사용할 경우 모델의 성능이 저하될 수 있습니다.
    * **해결책:** 
        - 데이터의 특성을 파악하고 모델이 요구하는 가정을 충족시키기 위해 적절한 데이터 변환(Data Transformation)을 수행하거나, 데이터의 특성에 더 적합한 알고리즘을 선택해야 합니다.
* **결과 오역:** 심층적인 분석 부족
    *  전체적인 평가 지표만으로는 모델의 성능을 충분히 이해하기 어렵습니다. 특정 하위 그룹(Subgroup)이나 특이 케이스(Edge Case)에서의 오류 패턴을 분석하지 않으면 모델의 약점을 파악하기 곤란.
    * **해결책:** 
        - 전체 평가 지표뿐만 아니라, 특정 하위 그룹별 성능, 오분류된 데이터의 특징 등을 분석하여 systematic error pattern을 발견하고, 실제 운영 환경에서의 잠재적인 문제점을 파악해야
* **메모리 관리 미흡:** 시스템 불안정의 원인
    *  대용량 데이터를 한 번에 로드하거나, 불필요한 변수를 계속 보관하거나, GPU 메모리를 적절히 관리하지 않으면 시스템 충돌(Crash)을 유발할 수 있습니다.
    * **해결책:** 
        - 데이터를 작은 배치(Batch) 단위로 처리하거나 데이터 생성기(Data Generator)를 사용하여 메모리 사용량을 최적화하고, 더 이상 사용하지 않는 변수는 메모리에서 해제하며, GPU 메모리 사용량을 주기적으로 확인하고 관리해야 합니다.
* **모델 편향 미확인:** 공정성 문제 야기
    *  훈련 데이터에 내재된 인구 통계적 편향(Demographic Bias)이나 특정 데이터만 선택되어 발생하는 선택 편향(Selection Bias) 등이 모델 학습에 반영되어 특정 그룹에 불리한 예측 결과를 초래
    * **해결책:** 
        - 다양한 하위 그룹 및 시나리오에서 모델 성능을 테스트하고, 인구 통계적 특성별 예측 결과를 확인하여 모델에 편향이 존재하는지 확인해야 합니다. 발견된 편향은 명확하게 문서화하고, 편향을 완화하기 위한 노력을 기울여야 합니다.
* **부실한 문서화:** 협업 및 재현성 저해
    *  데이터 소스, 전처리 단계, 모델 파라미터, 실험 결과 등을 제대로 기록하지 않으면 문제 발생 시 원인을 파악하기 어렵고, 다른 사람과의 협업이 어려워지며, 과거 실험을 재현하는 것이 불가능해집니다.
    * **해결책:** 
        - 데이터의 출처, 전처리 과정, 모델의 하이퍼파라미터, 실험 결과 등을 상세하게 기록하고 관리해야
* **버전 관리 미흡:** 개발 과정 추적의 어려움
    *  코드 변경 이력, 사용한 데이터셋, 학습된 모델 등을 버전 관리하지 않으면 코드 변경 추적, 과거 실험 재현, 협업 과정에서 혼란이 발생할 수 있습니다.
    * **해결책:** 
        - Git과 같은 버전 관리 시스템을 사용하여 코드 변경 이력을 관리하고, DVC(Data Version Control)나 MLflow와 같은 도구를 활용하여 데이터와 모델의 버전을 관리하는 것이 중요합니다.



## 8. 신경망 (Neural Networks) & Generative AI & GPT
- 출처: [Neural Networks in 100 seconds](https://www.youtube.com/watch?v=3TeEqgqPK8M)

### 8.1 신경망
**1. 정의:**
* 인간 뇌의 복잡한 연결망에서 영감을 받아 설계된 현대 인공지능의 **가장 핵심적인 모델 중 하나**입니다.
* 단순한 선형 회귀 모델을 **여러 층으로 쌓아 올리고 각 층에서 비선형 함수를 적용**하여 데이터 내의 복잡하고 **숨겨진 패턴과 관계**를 효과적으로 파악하고 **일반화**하는 강력한 확장 모델입니다.

**2. 구조:**

* **뉴런 (노드):** 신경망을 구성하는 **가장 기본적인 정보 처리 단위**로, 뇌의 뉴런과 유사하게 입력된 정보를 받아 특정 연산을 수행한 후 결과를 다음 뉴런으로 전달합니다.
* **가중치:** 뉴런과 뉴런 사이의 연결 **강도 또는 중요도를 나타내는 숫자 값**으로, 학습 과정에서 데이터의 패턴에 맞춰 **자동으로 조정**되며, 어떤 연결이 더 중요한지를 결정합니다.
* **계층:**
    * **입력 계층:** 분석하고자 하는 **원시 형태의 데이터** (예: 이미지의 픽셀 값, 텍스트의 단어 임베딩 값 등)가 신경망으로 처음 입력되는 계층입니다.
    * **숨겨진 계층:** 입력 계층과 출력 계층 사이에 **하나 또는 여러 개 존재**하며, 입력된 데이터를 **다양한 방식으로 변환하고 추상화**하여 복잡한 특징을 추출하는 핵심적인 역할을 수행합니다.
    * **출력 계층:** 신경망의 최종 **예측 또는 분류 결과**를 생성하는 계층입니다. 예를 들어, 이미지를 분류하는 신경망의 출력 계층은 각 클래스에 대한 확률 값을 나타낼 수 있습니다.

**3. 학습 방식:**

* **역전파 (Backpropagation):** 신경망이 예측한 결과와 실제 정답 간의 **오차를 계산**하고, 이 오차를 기반으로 신경망의 **가중치를 효율적으로 조정**하는 핵심 알고리즘입니다.
    * 마치 "따뜻하다/차갑다" 게임처럼, 초기에는 무작위로 설정된 가중치를 **오차를 줄이는 방향으로 점진적으로 반복하여 조정**함으로써 신경망의 정확도를 높여나갑니다.

**4. 특징 및 능력:**

* **방대한 양의 데이터**에서 인간이 직관적으로 파악하기 어려운 **미묘하고 복잡한 패턴**을 스스로 학습하고 발견하는 뛰어난 능력을 가지고 있습니다.
* **이미지 인식, 자연어 처리 (언어 번역, 텍스트 생성 등), 음성 인식, 게임, 로봇 제어, 예술 생성** 등 매우 다양한 분야에서 혁신적인 성과를 보여주고 있습니다.
* 신경망의 **계층이 깊어질수록 (심층 신경망)** 더욱 추상적이고 복잡한 데이터의 특징을 학습할 수 있어, **더욱 정교한 작업 수행**이 가능해집니다.

**5. 종류:**

* **CNN (Convolutional Neural Networks):** 이미지의 공간적 특징을 효과적으로 추출하도록 설계되어 **이미지 인식, 객체 탐지 등 이미지 처리** 분야에서 뛰어난 성능을 보입니다.
* **RNN (Recurrent Neural Networks):** **순차적인 데이터 (시계열 데이터, 텍스트 등)**의 이전 정보를 기억하고 활용하는 데 특화되어 있어, 자연어 처리, 음성 인식 등에 활용됩니다.
* **Transformer:** **Attention 메커니즘**을 도입하여 장거리 의존성을 효과적으로 모델링하며, **자연어 처리 분야에서 획기적인 성능 향상**을 가져왔고, 현재 다양한 분야로 확장되고 있습니다.

**6. 개발 환경:**

* **TensorFlow, PyTorch**와 같은 고성능 **오픈소스 딥러닝 프레임워크**는 신경망 모델의 설계, 학습, 배포에 필요한 다양한 도구와 기능을 제공하여, 복잡한 수학적 배경 지식 없이도 비교적 쉽게 신경망 모델을 개발하고 실험할 수 있도록 지원합니다.

### 8.2 Generative AI 

**1. 정의:**

* 기존에 학습한 데이터를 기반으로 **새롭고 독창적인 콘텐츠** (이미지, 텍스트, 음악, 코드, 비디오 등)를 **자율적으로 생성**할 수 있는 지능형 시스템입니다.
* **DALL-E의 놀라운 그림 생성 능력**이나 **ChatGPT의 인간과 유사한 자연스러운 대화 능력** 등이 Generative AI의 대표적인 성공 사례입니다.

**2. 핵심 원리:**

* Generative AI는 **방대한 양의 기존 데이터에서 데이터의 분포와 패턴을 학습**하고, 학습된 내용을 바탕으로 **기존 데이터와 유사하면서도 새로운 특성을 가진 콘텐츠를 생성**합니다.
* 이는 마치 **수백만 장의 다양한 그림을 보고 화풍과 기법을 익혀 새로운 그림을 창작하는 화가**나, **인터넷 전체의 방대한 텍스트 데이터를 읽고 이해하여 새로운 이야기를 써내는 작가**와 유사하게 작동합니다.

**3. 이미지 생성 기술:**

* **GAN (Generative Adversarial Networks):**
    * **진짜 같은 이미지를 생성하는 '생성자 (Generator)'**와 **생성된 이미지가 진짜인지 가짜인지 판별하는 '판별자 (Discriminator)'**라는 두 개의 신경망이 **서로 경쟁하며 발전**하는 구조입니다.
    * 생성자는 판별자를 속이기 위해 점점 더 현실적인 가짜 이미지를 생성하고, 판별자는 가짜 이미지를 정확하게 식별하도록 학습하는 과정을 반복하면서, **결국 생성자는 실제 이미지와 구별하기 어려울 정도로 정교한 이미지를 생성**할 수 있게 됩니다.
* **Diffusion Models (Stable Diffusion):**
    * 원본 이미지에 **점진적으로 노이즈를 추가하는 과정**과, **노이즈가 추가된 이미지에서 원래 이미지를 복원하는 역과정을 학습**하는 방식입니다.
    * 학습된 역과정을 통해 **텍스트 프롬프트와 같은 조건**을 기반으로 **무작위 노이즈에서 시작하여 사용자가 원하는 새로운 이미지를 생성**할 수 있습니다.

**4. 텍스트 및 코드 생성 기술:**

* **Large Language Models (GPT):**
    * 주어진 문맥에서 **다음에 이어질 가장 가능성 높은 단어 (토큰)를 예측하는 과정을 반복**하여 **일관성 있고 문법적으로 자연스러운 텍스트를 생성**합니다.
    * 방대한 텍스트 데이터를 학습하여 **인간 언어의 복잡한 패턴과 의미를 이해**하고, 이를 바탕으로 다양한 형태의 텍스트 생성이 가능합니다.
* **코드 생성 도구 (Devon):**
    * GPT와 유사한 원리로 작동하여 **자연어 설명을 이해하고 그에 맞는 코드를 자동으로 생성**함으로써, 프로그래머의 생산성을 크게 향상시키는 데 기여합니다.

**5. 멀티모달 모델:**

* **이미지 이해, 텍스트 생성, 코드 생성, 비디오 편집** 등 **다양한 유형의 콘텐츠를 통합적으로 처리하고 생성**할 수 있는 AI 모델입니다.
* 이는 AI가 단순히 하나의 유형의 콘텐츠만 생성하는 것을 넘어, **여러 유형의 정보를 이해하고 상호 작용하며 더욱 풍부하고 복합적인 콘텐츠를 생성**할 수 있도록 AI의 가능성을 확장합니다.

**6. 한계 및 윤리적 고려 사항:**

* Generative AI는 학습 데이터의 패턴을 기반으로 새로운 콘텐츠를 생성하지만, **인간과 같은 진정한 의미의 창의성이나 독창성을 갖기는 어렵습니다.** 즉, 완전히 새로운 아이디어를 스스로 만들어내는 능력은 부족합니다.
* 학습 데이터에 **편향된 정보가 포함되어 있을 경우, 생성된 콘텐츠에도 편향이 반영**되거나 **오해를 불러일으킬 수 있는 잘못된 정보가 생성**될 수 있습니다.
* Generative AI 기술의 발전은 **저작권 침해, 가짜 뉴스 생성, 악의적인 콘텐츠 제작** 등 다양한 **윤리적 문제**를 야기할 수 있으며, 이에 대한 심각한 고민과 대비가 필요합니다.

### 8.3 GPT (Generative Pre-trained Transformer)

**1. 핵심:**

* **현대 자연어 처리 분야에서 가장 영향력 있는 최첨단 AI 언어 모델의 기반이 되는 핵심 아키텍처**입니다.
* GPT 모델은 **기계가 인간의 언어를 이해하고 생성하는 방식에 혁신적인 변화**를 가져왔으며, 다양한 자연어 처리 task에서 뛰어난 성능을 보여주고 있습니다.

**2. 특징:**

* **Transformer 모델:** 텍스트 내의 **각 단어 (토큰) 간의 관계와 중요도를 효과적으로 파악**하는 **Attention 메커니즘**이라는 혁신적인 기술을 핵심으로 사용하여 텍스트를 처리합니다.
* **Generative (생성적):** 주어진 문맥을 이해하고, 그 다음에 이어질 **가장 적절한 단어 (토큰)를 순차적으로 예측**하여 **새로운 텍스트를 자연스럽게 생성**하는 능력을 가지고 있습니다.
* **Pre-trained (사전 학습):** **인터넷상의 방대한 양의 텍스트 데이터**를 이용하여 언어의 기본적인 규칙, 문법, 의미, 그리고 다양한 지식을 **미리 학습**한 후, 특정 작업 (예: 텍스트 분류, 질문 답변, 번역 등)에 맞춰 **추가적인 미세 조정 (fine-tuning)** 과정을 거쳐 활용됩니다.
* **Self-Attention:** Transformer 모델의 핵심 메커니즘으로, **하나의 문장 내에서 각 단어가 다른 단어들과 어떤 관계를 맺고 있는지**를 여러 레이어를 거치면서 다각도로 분석하고 집중하여 **텍스트의 맥락을 깊이 있게 이해**할 수 있도록 합니다. 이를 통해 문법적인 구조뿐만 아니라 의미론적인 관계, 그리고 사실 관계까지 파악할 수 있습니다.
* **단어 벡터화 (Word Embedding):** 텍스트 속의 각 단어를 **고차원 공간의 벡터로 표현**하는 기술로, **의미가 유사한 단어들은 벡터 공간에서 서로 가까운 위치에 놓이게 됩니다.** 이를 통해 모델은 단어의 의미적 유사성을 파악하고 활용할 수 있습니다.
* **Attention Score 계산:** Self-Attention 과정에서 각 단어가 문맥 내의 다른 단어들에 대해 가지는 **상대적인 중요도를 수치화**한 값입니다. 이 점수를 통해 모델은 문맥을 이해하는 데 **더 중요한 단어에 더 많은 집중**을 할 수 있습니다.

**3. 규모:**

* GPT 모델은 **매우 큰 규모의 데이터셋**을 사용하여 학습되며, 학습 과정에 **막대한 양의 컴퓨팅 자원**이 필요합니다.
* **GPT-3** 모델은 약 **1,750억 개**의 파라미터를 가지고 있으며, 더욱 발전된 모델인 **GPT-4**는 약 **1조 8천억 개**에 달하는 훨씬 더 많은 파라미터를 가지고 있습니다. 모델의 크기가 커질수록 일반적으로 성능이 향상되는 경향을 보입니다.

**4. 한계:**

* **사실 왜곡 (Hallucination):** 때로는 **사실과 다르거나 논리적으로 맞지 않는 정보**를 마치 사실인 것처럼 생성하는 경향이 있습니다. 이는 모델이 완벽하게 세상을 이해하는 것이 아니라, 학습 데이터의 패턴을 기반으로 텍스트를 생성하기 때문에 발생할 수 있습니다.
* **인간과 같은 진정한 맥락 이해 부족:** 겉으로는 유창한 텍스트를 생성하지만, **인간과 같은 깊이 있는 이해나 추론 능력은 아직 부족**할 수 있습니다. 특히 복잡한 상황이나 암묵적인 의미를 이해하는 데 어려움을 겪을 수 있습니다.
* **학습 데이터에 따른 편향:** 학습 데이터에 존재하는 **사회적 편견이나 잘못된 정보가 모델의 출력에 그대로 반영**될 수 있습니다. 이는 모델의 공정성과 윤리적인 측면에서 중요한 문제로 지적됩니다.

**5. 결론:**

* GPT 모델은 텍스트 생성 및 이해 능력에서 **매우 강력한 도구**임에는 분명하지만, **인간과 같은 수준의 완전한 인공 일반 지능 (Artificial General Intelligence, AGI)에는 아직 미치지 못합니다.** 지속적인 연구와 개선을 통해 이러한 한계를 극복하고 더욱 발전된 AI 모델로 나아갈 것으로 기대됩니다.

## 9. 22가지 머신러닝 프로젝트 로드맵 
- 출처: [22 Machine Learning Projects That Will Make You A God At Data Science](https://www.youtube.com/watch?v=QlbyGPVaRSE&t=48s)

- 이 로드맵은 머신러닝 학습 여정을 체계적으로 안내하기 위해 **다양한 난이도와 실질적인 주제**를 아우르는 22개의 머신러닝 프로젝트를 소개합니다. 각 프로젝트는 **구체적인 목표와 학습 내용**을 제시하며, 난이도, 이력서 가치, 학습 가치, 실제 영향력이라는 네 가지 핵심 측면에서 심층적으로 평가됩니다. 이를 통해 학습자는 자신의 현재 수준을 파악하고, **단계별 성장**을 위한 맞춤형 학습 계획을 수립할 수 있습니다.


### **9.1 기초 다지기: 머신러닝의 기본 개념과 도구를 익히는 단계**

1.  **탐색적 데이터 분석 (EDA) 포트폴리오**: 
    - 주어진 데이터를 시각화하고 요약하여 데이터의 특성, 패턴, 이상치 등을 파악하는 기본적인 과정
        * 난이도: 2/10 (Python 라이브러리 활용 능력)
        * 이력서 가치: 3/10 (기본적인 데이터 분석 능력 어필)
        * 학습 가치: 5/10 (**데이터 과학자의 업무 중 80%**를 차지할 정도로 중요한 기초 역량 이해)
        * 영향력: 4/10 (향후 진행할 **모든 머신러닝 프로젝트의 기반**이 됨)

2.  **Iris 꽃 분류**: 
    - Scikit-learn 라이브러리에 내장된 간단한 데이터셋을 이용하여 기본적인 분류 알고리즘(예: 로지스틱 회귀, 의사결정나무)을 학습하고 평가하는 프로젝트입니다.
        * 난이도: 2/10 (Scikit-learn 사용법 숙지)
        * 이력서 가치: 2/10 (입문 수준의 프로젝트)
        * 학습 가치: 6/10 (**지도 학습의 핵심인 분류 알고리즘의 기본 원리** 이해)
        * 영향력: 3/10 (머신러닝의 기본적인 문제 해결 , **식물학 등 특정 분야에 관심 있다면** 응용)

3.  **선형 회귀 직접 구현**: 
    - 라이브러리를 사용하지 않고 Python과 NumPy만으로 선형 회귀 알고리즘을 직접 구현하여 머신러닝 모델의 내부 작동 방식을 깊이 이해하는 데 목표를 둡니다.
        * 난이도: 5/10 (선형대수학, 미적분학 기초 필요)
        * 이력서 가치: 6/10 (머신러닝 **핵심 원리에 대한 깊이 있는 이해** 어필)
        * 학습 가치: 9/10 (**머신러닝 알고리즘이 어떻게 데이터를 학습하고 예측하는지** 근본적인 이해, 오류 발생 시 **디버깅 시간 절약**에 크게 기여)
        * 영향력: 6/10 (다른 복잡한 모델의 **기본 원리를 이해하는 토대** 마련)

### **9.2 실전 경험 쌓기: 다양한 머신러닝 문제 해결 능력을 키우는 단계**

4.  **Titanic 생존 예측**: 
    - Kaggle 경진대회에서 유명한 Titanic 데이터셋을 이용하여 탑승객의 여러 특징(나이, 성별, 객실 등)을 기반으로 생존 여부를 예측하는 분류 모델을 개발합니다.
        * 난이도: 3/10 (데이터 전처리, 기본적인 분류 모델 적용)
        * 이력서 가치: 3/10 (Kaggle 참여 경험 어필)
        * 학습 가치: 7/10 (**결측치 처리, Feature Engineering** 등 실제 데이터 분석에 필수적인 기술)
        * 영향력: 4/10 (실제 **이진 분류 문제**에 머신러닝을 적용하는 경험)

5.  **주택 가격 예측**: 
    - Boston Housing 데이터셋 또는 유사한 실제 주택 가격 데이터를 이용하여 다양한 특징(위치, 크기, 편의시설 등)을 기반으로 주택 가격을 예측하는 회귀 모델을 개발합니다.
        * 난이도: 3/10 (데이터 전처리, 다양한 회귀 모델 적용 및 평가)
        * 이력서 가치: 4/10 (회귀 분석 모델링 경험 어필)
        * 학습 가치: 7/10 (**회귀 분석의 핵심 개념 이해, Feature Selection** 기법 학습)
        * 영향력: 5/10 (**주거 문제 해결** 또는 부동산 시장 분석에 머신러닝 적용 가능성 시사)

6.  **이미지 분류 시스템 (고양이 vs 개)**: 
    - 작은 규모의 이미지 데이터셋을 이용하여 Convolutional Neural Network (CNN) 모델을 구축하고 훈련하여 고양이와 개 이미지를 분류하는 시스템을 개발합니다.
        * 난이도: 6/10 (CNN 기본 구조 이해, 이미지 데이터 전처리)
        * 이력서 가치: 7/10 (**컴퓨터 비전 분야**에 대한 관심과 기본 역량 어필)
        * 학습 가치: 8/10 (**CNN의 작동 원리, 이미지 데이터 전처리 및 증강** 기법 습득)
        * 영향력: 8/10 (**컴퓨터 비전** 기술의 다양한 응용 가능성 확인)

7.  **감성 분석 시스템**: 
    - 텍스트 데이터(예: 영화 리뷰, 소셜 미디어 게시글)를 이용하여 긍정, 부정 또는 중립적인 감성을 분류하는 자연어 처리 (NLP) 모델을 개발합니다.
        * 난이도: 5/10 (텍스트 데이터 전처리, 기본적인 NLP 모델 적용)
        * 이력서 가치: 7/10 (**자연어 처리 분야**에 대한 관심과 기본 역량 어필)
        * 학습 가치: 8/10 (**텍스트 데이터 전처리, 다양한 언어 처리 모델** (예: Bag-of-Words, TF-IDF, Word Embeddings) 이해)
        * 영향력: 8/10 (실제 **텍스트 데이터 기반의 다양한 분석** 가능성 제시)

8.  **고객 이탈 예측**: 
    - 고객의 행동 데이터(구매 기록, 서비스 이용 내역 등)를 분석하여 특정 고객이 서비스를 이탈할 가능성을 예측하는 분류 모델을 개발합니다.
        * 난이도: 4/10 (불균형 데이터 처리, 비즈니스 지표 이해)
        * 이력서 가치: 6/10 (비즈니스 문제 해결 능력 어필)
        * 학습 가치: 7/10 (**불균형 데이터 처리 기법, 비즈니스 성과 지표 활용** 방법 학습)
        * 영향력: 7/10 (기업의 **수익 증대**에 직접적으로 기여할 수 있는 모델 개발)

9.  **주가 예측**: 
    - 과거 주가 데이터를 이용하여 미래의 주가를 예측하는 시계열 분석 모델을 개발합니다. (단, 주가 예측은 매우 어려운 문제임을 인지해야 합니다.)
        * 난이도: 6/10 (시계열 데이터 특성 이해, Feature Engineering)
        * 이력서 가치: 7/10 (시계열 데이터 분석 능력 어필)
        * 학습 가치: 8/10 (**시계열 데이터 처리, Feature Engineering** 기법, 순환 신경망(RNN) 기초)
        * 영향력: 8/10 (**금융 시장 분석**에 머신러닝 적용 가능성 탐색)

### 9.3 **심화 학습: 딥러닝 및 고급 머신러닝 개념을 깊이 있게 이해하는 단계**

10. **신경망 직접 구현**: 
    - 딥러닝 프레임워크(TensorFlow, PyTorch)를 사용하지 않고 Python과 NumPy만으로 기본적인 신경망 구조(Fully Connected Layer, 활성화 함수 등)를 직접 구현하여 딥러닝 모델의 내부 작동 원리를 완벽하게 이해하는 데 목표를 둡니다.
        * 난이도: 8/10 (선형대수학, 미적분학, 확률 및 통계 심화 이해)
        * 이력서 가치: 8/10 (**딥러닝의 핵심 원리에 대한 깊이 있는 이해**를 보여주는 강력한 증거)
        * 학습 가치: 10/10 (**딥러닝 모델이 어떻게 학습하고 예측하는지** 근본적인 이해, 최신 **AI 논문 이해도 향상**에 필수적)
        * 영향력: 8/10 (복잡한 딥러닝 모델 개발 및 디버깅 능력 향상)

11. **실시간 얼굴 인식 시스템**: 
    - 웹캠 등을 통해 입력되는 실시간 영상에서 얼굴을 감지하고, 미리 등록된 얼굴 데이터베이스와 비교하여 누구인지 식별하는 시스템을 구축합니다.
        * 난이도: 8/10 (컴퓨터 비전, 딥러닝, 실시간 처리 기술)
        * 이력서 가치: 9/10 (**컴퓨터 비전 및 딥러닝** 실력 입증, **보안 시스템 및 개인 식별** 분야 응용 가능성 시사)
        * 학습 가치: 9/10 (얼굴 감지 및 인식 알고리즘, 딥러닝 모델 활용, 실시간 데이터 처리 기술 습득)
        * 영향력: 9/10 (**보안 시스템 강화, 개인 식별 기술 발전**에 기여)

12. **추천 시스템**: 
    - 사용자-아이템 상호작용 데이터(구매 기록, 평점 등)를 분석하여 특정 사용자에게 맞춤형 아이템을 추천하는 시스템을 개발합니다.
        * 난이도: 6/10 (**협업 필터링, 콘텐츠 기반 추천** 알고리즘 이해 및 구현)
        * 이력서 가치: 8/10 (**추천 시스템** 개발 경험은 **온라인 서비스 분야**에서 높은 가치)
        * 학습 가치: 8/10 (**협업 필터링, 콘텐츠 기반 추천** 등 다양한 추천 알고리즘 이해 및 구현, 사용자 행동 데이터 분석)
        * 영향력: 9/10 (**온라인 서비스 사용자 경험 개인화 및 만족도 향상**, 매출 증대에 기여)

### **9.4 전문가 영역: 머신러닝 시스템 구축 및 운영 능력을 배우는 단계**

13. **자동화된 ML 파이프라인**: 
    - 데이터 수집, 전처리, 모델 학습, 평가, 배포 등 머신러닝 모델 개발의 전 과정을 자동화하는 파이프라인을 구축합니다.
        * 난이도: 7/10 (MLOps 기본 개념 이해, 자동화 도구 활용)
        * 이력서 가치: 9/10 (**ML 엔지니어링** 역량 어필, 효율적인 머신러닝 개발 프로세스 구축 능력 강조)
        * 학습 가치: 9/10 (**MLOps의 핵심 개념 및 도구** 이해, **데이터 과학 워크플로우 자동화** 경험)
        * 영향력: 9/10 (머신러닝 모델 개발 및 배포 효율성 극대화)

14. **언어 모델 직접 구현**: 
    - Transformer 아키텍처의 기본적인 부분을 직접 구현하여 최신 자연어 처리 모델의 핵심 원리를 깊이 있게 이해합니다. (BERT, GPT와 같은 거대 언어 모델의 기반 학습)
        * 난이도: 9/10 (Transformer 아키텍처 심층 이해, 고급 NLP 개념)
        * 이력서 가치: 9/10 (**최신 NLP 기술**에 대한 깊이 있는 이해 입증)
        * 학습 가치: 10/10 (**Transformer 구조의 작동 원리 완벽 이해**, **자연어 처리 모델 개발** 능력 향상)
        * 영향력: 9/10 (차세대 **자연어 처리 기술 개발**에 기여 가능성 제시)

15. **AB 테스팅 프레임워크**: 
    - 개발한 머신러닝 모델의 성능을 실제 환경에서 효과적으로 검증하기 위한 AB 테스팅 프레임워크를 설계하고 구현합니다.
        * 난이도: 7/10 (통계적 가설 검정, 실험 설계 원리 이해)
        * 이력서 가치: 8/10 (**데이터 기반 의사 결정** 능력, **실험 설계 및 분석** 역량 어필)
        * 학습 가치: 10/10 (**통계적 가설 검정, 실험 설계 및 분석 방법론** 심층 학습, **실제 데이터 기반 의사 결정** 프로세스 이해)
        * 영향력: 8/10 (**실제 서비스 개선 및 효과 측정** 능력 향상)

16. **이미지 생성 시스템**: 
    - Generative Adversarial Networks (GANs)와 같은 생성 모델을 이용하여 새로운 이미지를 생성하는 시스템을 구축합니다.
        * 난이도: 9/10 (GANs 및 다양한 이미지 생성 모델 심층 이해)
        * 이력서 가치: 8/10 (**AI 아트, 콘텐츠 생성** 등 창의적인 분야에 대한 관심과 기술 어필)
        * 학습 가치: 9/10 (**GANs 및 다양한 이미지 생성 모델의 작동 원리** 이해, **AI 기반 콘텐츠 생성** 기술 습득)
        * 영향력: 8/10 (**AI 아트, 새로운 콘텐츠 생성** 등 다양한 분야에 응용 가능성 제시)

17. **다국어 NLP 파이프라인**: 
    - 여러 언어의 텍스트 데이터를 처리하고 분석할 수 있는 NLP 파이프라인을 구축합니다. (다국어 임베딩, 번역 모델 활용)
        * 난이도: 8/10 (다국어 임베딩 기법, 번역 모델 활용)
        * 이력서 가치: 9/10 (**글로벌 서비스 지원**에 필요한 핵심 기술 보유 어필)
        * 학습 가치: 9/10 (**다국어 임베딩 기법 이해, 번역 시스템 구축 원리 학습**, 다양한 언어 데이터 처리 경험)
        * 영향력: 9/10 (**글로벌 서비스의 품질 향상 및 사용자 확대**에 기여)

18. **강화 학습 게임**: 
    - OpenAI Gym과 같은 환경을 이용하여 스스로 학습하는 게임 AI 에이전트를 개발합니다. (보상 함수 설계, 정책 기울기 알고리즘 이해)
        * 난이도: 8/10 (**강화 학습 기본 개념 (보상 함수, 정책 등) 이해, 관련 알고리즘 구현**)
        * 이력서 가치: 7/10 (**게임 AI, 자동 제어** 분야에 대한 관심과 기본 역량 어필)
        * 학습 가치: 9/10 (**강화 학습의 핵심 개념 및 다양한 알고리즘** 이해, **보상 시스템 설계** 능력 함양)
        * 영향력: 8/10 (**게임 AI 개발, 로봇 제어 등 다양한 자동화 시스템** 개발에 응용 가능)

19. **실시간 사기 탐지 시스템**: 
    - 금융 거래 데이터를 실시간으로 분석하여 사기 거래를 탐지하는 시스템을 구축합니다. (불균형 데이터 처리, 금융 데이터 Feature Engineering)
        * 난이도: 8/10 (**불균형 데이터 처리 심화 기법, 금융 데이터 특성 이해 및 Feature Engineering**)
        * 이력서 가치: 9/10 (**금융 보안** 분야에 대한 높은 이해도 및 기술력 어필)
        * 학습 가치: 9/10 (**실시간 데이터 처리, 불균형 데이터 처리 심화 기법**, 금융 데이터 분석 및 Feature Engineering 능력 향상)
        * 영향력: 10/10 (**금융 보안 강화 및 소비자 보호**에 직접적으로 기여)

### **9.5 최종 보스: 머신러닝의 모든 것을 아우르는 전문가 수준의 프로젝트**

20. **AutoML 직접 구현**: 
    - 데이터와 목표를 설정하면 자동으로 최적의 머신러닝 모델을 탐색하고 구축하는 AutoML 시스템의 핵심 기능을 직접 구현합니다. (모든 ML 기술 통합)
        * 난이도: 9/10 (**지금까지 학습한 모든 머신러닝 기술 및 지식의 통합적 활용**)
        * 이력서 가치: 10/10 (**최고 수준의 머신러닝 전문가**임을 입증)
        * 학습 가치: 10/10 (**머신러닝 모델 개발 전 과정에 대한 깊이 있는 이해 및 자동화 능력 함양**)
        * 영향력: 9/10 (**데이터 과학 워크플로우 혁신 및 생산성 향상**에 크게 기여)

21. **MLOps 파이프라인**: 
    - 개발된 머신러닝 모델을 실제 서비스 환경에 안정적으로 배포하고 지속적으로 모니터링하며 유지보수하는 MLOps 파이프라인 전체를 구축합니다. (모델 배포, CI/CD, 모니터링)
        * 난이도: 9/10 (**머신러닝 모델 배포 및 운영 전반에 대한 깊이 있는 이해**)
        * 이력서 가치: 10/10 (**실제 서비스 환경에 머신러닝 모델을 적용하고 관리**하는 핵심 역량 어필)
        * 학습 가치: 10/10 (**모델 배포 전략, CI/CD 파이프라인 구축, 모델 성능 모니터링 및 유지보수** 기술 습득)
        * 영향력: 10/10 (**머신러닝 모델의 실제 서비스 적용 및 지속적인 가치 창출**에 필수적인 역할 수행)

22. **분산 ML 시스템**: 
    - 대규모 데이터를 효율적으로 처리하고 실시간으로 모델을 학습시키기 위한 분산 머신러닝 시스템을 설계하고 구축합니다. (대규모 데이터 처리, 분산 학습 프레임워크 활용)
        * 난이도: 10/10 (**분산 시스템 아키텍처, 대규모 데이터 처리 기술, 분산 학습 프레임워크 심층 이해**)
        * 이력서 가치: 10/10 (**초대규모 머신러닝 시스템 구축 및 운영 능력**은 최고 수준의 전문가임을 의미)
        * 학습 가치: 10/10 (**대규모 데이터 처리, 분산 학습 알고리즘 및 프레임워크 활용 능력 극대화**)
        * 영향력: 10/10 (**초대규모 AI 서비스 개발 및 성능 향상**에 핵심적인 기여)

### **9.6 주의사항**

* **모든 프로젝트를 필수로 완료할 필요는 없습니다.** 자신의 관심 분야와 학습 목표에 맞춰 프로젝트를 선택하고 집중하는 것이 중요합니다.
* **자신의 현재 기술 수준을 정확히 파악하고, 감당할 수 있는 난이도의 프로젝트부터 시작**하여 점진적으로 난이도를 높여나가세요.
* **첫 시도가 완벽하지 않아도 괜찮습니다.** Chat GPT와 같은 뛰어난 결과물을 처음부터 기대하기보다는, 꾸준히 배우고 개선해 나가는 과정을 즐기세요.
* **포기하지 않고 꾸준히 노력한다면, 이 로드맵의 최종 목표인 AI 마법사에 도달**할 수 있을 것입니다. 끈기가 가장 중요한 요소입니다.

## 10. Transformer & 딥러닝 & Gradient Descent
- 출처: [Transformers](https://www.youtube.com/watch?v=QlbyGPVaRSE&t=48s)

### 10.1 Transformer 모델 
**1. 혁신적인 특징:**

* **순차적 데이터 처리 방식 혁신:** 기존 순환 신경망(RNN) 기반 모델들은 텍스트와 같은 순차적인 데이터를 앞에서부터 차례대로 처리해야 했지만, Transformer 모델은 **Self-Attention 메커니즘**을 활용하여 **전체 시퀀스를 병렬로 한 번에 처리**할 수 있습니다. 이는 긴 문장이나 문서에서도 정보 손실 없이 효율적인 학습을 가능하게 합니다.
* **다양한 분야 적용:** Transformer의 뛰어난 성능은 자연어 처리(NLP) 분야를 넘어 **텍스트 생성 (GPT), 이미지 인식 및 생성, 오디오 처리, 심지어 단백질 구조 예측** 등 다양한 분야로 확장되고 있습니다. 이는 Transformer의 핵심 메커니즘이 데이터의 순서나 형태에 구애받지 않고 **내부적인 관계성을 효과적으로 모델링**할 수 있기 때문입니다.

**2. 핵심 메커니즘:**

* **Self-Attention:** 문장 내 각 단어가 **다른 모든 단어와 어떤 관계를 맺고 있는지**를 파악하는 메커니즘입니다. 이를 통해 모델은 문맥 속에서 단어의 중요도를 스스로 학습하고, **장거리 의존성(멀리 떨어져 있는 단어들 간의 의미 관계)**도 효과적으로 연결할 수 있습니다.
    * 예시: "그것은 탁자 위에 있는 사과였다. **그것**은 매우 맛있었다."라는 문장에서 "it"이 무엇을 지칭하는지 파악하기 위해, Self-Attention은 "it"과 문맥 속의 다른 단어들("탁자", "위", "사과", "맛있었다")과의 관련성을 다양한 관점에서 고려하여 "**사과**"를 지칭한다는 것을 높은 확률로 추론합니다.

**3. 구조:**

* **Encoder (입력 이해) + Decoder (출력 생성):** Transformer 모델의 기본적인 구조는 입력 시퀀스를 이해하는 **Encoder**와 이해된 내용을 바탕으로 새로운 시퀀스를 생성하는 **Decoder**로 구성됩니다.
    * **BERT (Bidirectional Encoder Representations from Transformers):** 주로 텍스트의 의미를 깊이 있게 이해하는 데 특화되어 **Encoder**만을 사용합니다. (예: 텍스트 분류, 질의응답)
    * **GPT (Generative Pre-trained Transformer):** 텍스트를 자연스럽게 생성하는 데 특화되어 **Decoder**만을 사용합니다. (예: 텍스트 생성, Chatbot)
    * **번역 모델 (예: Google Translate):** 원문의 의미를 파악하고 다른 언어로 번역하기 위해 **Encoder와 Decoder**를 모두 사용합니다. Encoder가 원문의 정보를 압축하여 Decoder에 전달하면, Decoder는 이를 기반으로 번역된 문장을 생성합니다.
* **Token 변환 (Embedding):** 텍스트, 이미지, 기타 데이터는 모델이 이해할 수 있도록 **고차원 벡터 형태**로 변환됩니다. 이 과정을 **Token Embedding**이라고 하며, 각 토큰(단어, 이미지 조각 등)의 의미와 주변 토큰과의 관계 정보를 벡터 공간에 효과적으로 표현하는 것이 중요합니다.

**4. 학습 및 활용:**

* **대규모 데이터 및 컴퓨팅 자원 필요:** Transformer 모델은 복잡한 관계를 학습하기 위해 **매우 많은 양의 데이터**와 이를 효율적으로 처리할 수 있는 **고성능 컴퓨팅 자원 (GPU, TPU 등)**을 필요로 합니다.
* **다양한 작업 수행:** Transformer 모델은 입력과 출력의 형식을 적절히 변환함으로써 **텍스트 요약, 이미지 생성, 작곡, 코드 작성** 등 다양한 작업을 수행할 수 있습니다. 이는 사전 학습된 모델을 특정 작업에 맞게 **미세 조정(Fine-tuning)**하는 방식을 통해 이루어집니다.

**5. 한계:**

* **매우 긴 시퀀스 처리 어려움:** Self-Attention 연산은 입력 시퀀스 길이에 대해 제곱에 비례하는 계산 복잡도를 가지므로, **매우 긴 시퀀스를 처리하는 데 어려움**이 있습니다. 메모리 사용량과 계산 시간이 급격하게 증가하는 문제가 발생할 수 있습니다.
* **높은 계산 비용:** 모델의 크기가 커지고 학습 데이터 양이 증가함에 따라 **학습 및 추론에 필요한 계산 비용이 매우 높습니다.** 이는 모델 개발 및 활용에 큰 제약이 될 수 있습니다.
* **학습 데이터 패턴에 의존:** Transformer 모델은 결국 학습 데이터에서 나타나는 패턴을 학습하는 것이므로, **학습 데이터에 편향(bias)이 존재하거나 새로운 유형의 데이터에 대해서는 성능이 저하될 수 있습니다.**

### 10.2 딥러닝

**1. 정의:**

* 머신러닝의 하위 분야로, **인간의 신경망 구조를 모방한 다층 신경망(Deep Neural Network)**을 사용하여 이미지 인식, 자연어 처리 등 **기존 방식으로는 해결하기 어려웠던 복잡한 문제**를 해결합니다.
* **ChatGPT와 같은 거대 언어 모델, 테슬라의 자율주행차 시스템** 등 혁신적인 기술의 핵심 기반 기술로 다양한 분야에서 활용되고 있습니다.
* **명시적인 규칙이나 지시 없이** 방대한 양의 데이터를 스스로 학습하여 **데이터 속에 숨겨진 패턴을 발견하고 이를 기반으로 예측이나 분류** 등의 작업을 수행합니다.

**2. 구조:**

* **신경망:** 여러 개의 층(layer)으로 구성되어 있으며, 각 층은 입력된 데이터에서 **특정한 특징(feature)을 추출하고 감지하는 역할**을 수행하는 일종의 전문가와 같습니다. **층이 깊어질수록** 모델은 더욱 추상적이고 **복잡한 개념을 이해**할 수 있게 됩니다.
    * **초기층:** 이미지의 경우 기본적인 **모서리(edge), 색상(color)** 등을 감지합니다.
    * **중간층:** 초기층에서 감지된 특징들을 조합하여 **모양(shape), 질감(texture)** 등을 인식합니다.
    * **심층:** 중간층의 정보를 종합하여 **고양이, 강아지 등 더욱 복잡하고 의미 있는 객체나 개념을 이해**
* **3가지 핵심 구성 요소:**
    * **뉴런 (Neuron):** 신경망의 기본적인 정보 처리 단위로, 입력된 신호에 가중치를 곱하고 활성화 함수를 거쳐 출력을 생성합니다.
    * **가중치 (Weight):** 뉴런 간의 연결 강도를 나타내는 값으로, 학습 과정에서 **어떤 연결이 더 중요한지**를 결정합니다.
    * **활성화 함수 (Activation Function):** 각 뉴런의 출력을 결정하는 비선형 함수로, 신경망이 **비선형적인 복잡한 관계를 학습**할 수 있도록 합니다. 특정 임계값을 넘어야 뉴런이 활성화되어 다음 층으로 신호를 전달합니다.
* **학습 (Learning):** 모델의 예측과 실제 값 사이의 오류를 줄이기 위해 **역전파(back propagation)**라는 알고리즘을 통해 신경망의 **가중치를 반복적으로 조정**하는 과정입니다. 오류를 뒤로 전파하면서 각 가중치가 오류에 얼마나 기여했는지 계산하고, 그에 따라 가중치를 업데이트합니다.

**3. 특화된 구조:**

* **CNN (Convolutional Neural Network):** 이미지의 공간적 특징을 효과적으로 추출하기 위해 **합성곱(convolution) 연산**을 사용하는 신경망 구조로, **이미지 인식, 객체 탐지** 등에 주로 활용됩니다. 이미지 내의 **패턴을 지역적으로 스캔**하면서 특징을 추출합니다.
* **Transformer:** 텍스트와 같은 순차 데이터를 처리하는 데 특화된 구조로, **Self-Attention 메커니즘**을 통해 문장 내 **단어들 간의 관계를 효과적으로 모델링**하여 자연어 처리 분야에서 혁신적인 성능을 보여주고 있습니다.
* **GAN (Generative Adversarial Network):** **새로운 이미지, 텍스트, 오디오 등 콘텐츠를 생성**하는 데 사용되는 생성 모델로, **생성자(Generator)**와 **판별자(Discriminator)**라는 두 개의 신경망이 경쟁적으로 학습하면서 실제와 유사한 데이터를 만들어냅니다.

**4. 성공 요인:**

* **방대한 데이터 세트 (Large Datasets):** 딥러닝 모델은 복잡한 패턴을 학습하기 위해 **충분하고 다양한 학습 데이터**가 필수적입니다. 최근 몇 년간 데이터 수집 및 저장 기술의 발전으로 대규모 데이터셋 구축이 가능해졌습니다.
* **강력한 GPU (Graphics Processing Units):** 딥러닝 모델의 학습에는 엄청난 양의 병렬 연산이 필요하며, **GPU는 이러한 연산을 효율적으로 처리**하여 학습 시간을 크게 단축시켰습니다.
* **PyTorch, TensorFlow 등의 프레임워크:** 딥러닝 모델 개발을 위한 **고수준의 API와 다양한 도구를 제공하는 오픈소스 프레임워크**의 발전은 연구자와 개발자들이 복잡한 모델을 더 쉽게 설계하고 실험할 수 있도록 지원합니다. 이러한 프레임워크는 **복잡한 수학적 연산을 자동화**하여 개발 편의성을 높입니다.

**5. 특징 및 한계:**

* **패턴 인식 기반:** 딥러닝 모델은 결국 **데이터에서 나타나는 패턴을 학습**하는 것이며, 내부적으로는 **수백만 개의 선형 회귀 모델이 복잡하게 연결되어 함께 작동하는 것과 유사**하게 볼 수 있습니다.
* **학습 데이터의 패턴만 학습 가능:** 모델은 학습 데이터에 존재하지 않는 패턴이나 새로운 유형의 입력에 대해서는 제대로 작동하지 못할 수 있습니다.
* **인간은 쉽게 구별할 수 있는 것도 속을 수 있음 (Adversarial Attack):** 적대적 공격(adversarial attack)과 같이 인간은 쉽게 인식할 수 없는 미묘한 노이즈를 입력에 추가해도 모델의 예측이 완전히 틀릴 수 있습니다.
* **매우 강력하지만 결국 도구일 뿐:** 딥러닝은 매우 강력한 도구이지만, **스스로 사고하거나 이해하는 것은 아니며**, 주어진 데이터와 학습 목표에 따라 작동합니다.

### 10.3 경사 하강법 (Gradient Descent) 

**1. 정의:**

* **현대 머신러닝, 특히 딥러닝 모델 학습의 핵심적인 최적화 알고리즘**으로, 모델이 예측한 값과 실제 값의 차이(오류)를 최소화하는 최적의 파라미터(가중치)를 찾는 데 사용됩니다.
* **신경망 학습, 자연어 처리 모델 개선, 다양한 인공지능 문제 해결의 기본적인 원리**이며, 복잡한 모델을 데이터에 맞춰 학습시키는 데 필수적인 방법입니다.
* **수학적인 개념(미분)을 기반으로 하여 AI가 시행착오를 통해 점진적으로 학습하는 방식**을 가능하게 합니다. 모델의 성능을 개선하기 위해 파라미터를 어떤 방향으로 얼마나 조정해야 할지를 결정하는 핵심적인 역할

**2. 원리:**

* 모델의 **오류(Error)를 함수의 값으로 하는 다차원 공간(Error Landscape)**에서 **가장 낮은 지점, 즉 오류가 최소화되는 최적의 파라미터 조합(최적해)**을 찾아 이동하는 과정에 비유할 수 있습니다.
* 각 **모델 파라미터(가중치)**의 아주 **작은 변화가 전체 오류에 미치는 영향(기울기, Gradient)**을 수학적으로 계산합니다.
* 계산된 기울기의 **반대 방향(오류를 줄이는 방향)**으로 파라미터를 아주 조금씩 **단계적으로 업데이트**하면서 최적해에 접근합니다. 마치 언덕에서 공을 굴려 가장 낮은 지점으로 보내는 것과 유사합니다.

**3. 주요 개념:**

* **Gradient (기울기):** 현재 파라미터 값에서 **오류 함수가 가장 가파르게 증가하는 방향**을 나타내는 벡터입니다. 따라서 오류를 줄이기 위해서는 이 기울기의 **정반대 방향**으로 파라미터를 조정해야 합니다.
* **Learning Rate (학습률):**
    * 최적해를 찾아 언덕을 내려갈 때 **한 번에 이동하는 발걸음의 크기**에 해당합니다.
    * **너무 크면** 최저점을 지나쳐 발산하거나 불안정한 학습이 될 수 있고, **너무 작으면** 최저점에 도달하는 데 너무 많은 시간이 걸리거나 Local Minima에 갇힐 수 있습니다.
    * **Adam, SGD with Momentum** 등 다양한 **최적화 알고리즘**들은 학습 과정에서 이 **학습률을 자동으로 조절**하여 학습 효율성을 높입니다.
* **Mini-batch Gradient Descent:**
    * **전체 학습 데이터를 한 번에 사용하여 기울기를 계산하는 대신**, 무작위로 선택된 **작은 데이터 샘플(미니 배치)**을 사용하여 기울기를 계산하고 파라미터를 업데이트하는 방식입니다.
    * 전체 데이터를 사용하는 것에 비해 **계산량을 줄여 학습 속도를 향상**시키고, 각 업데이트에 노이즈를 추가하여 **Local Minima (국소 최솟값)에서 벗어나는 데 도움**을 줄 수 있습니다.
* **Error Landscape (오류 지형):**
    * 모델의 파라미터 값에 따른 **오류 값의 변화를 시각적으로 나타낸 형태**입니다. 실제로는 매우 복잡한 다차원 공간입니다.
    * 오류 지형의 형태는 학습의 **어려움을 야기**할 수 있습니다. 예를 들어, **평탄한 지역(학습이 매우 느려짐), Local Minima (최적해가 아닌 지역 최저점에 갇힘), 급격한 경사면(학습이 불안정해짐), 여러 개의 계곡(최적해를 찾기 어려움)** 등이 존재할 수 있습니다.
* **Momentum (모멘텀):** 이전 업데이트 방향의 일부를 현재 업데이트에 반영하여 **평탄한 지역을 빠르게 벗어나고 Local Minima에 갇히는 것을 방지**하는 데 도움을 주는 기법입니다. 마치 언덕에서 공이 관성에 의해 계속 굴러가는 것과 유사합니다.
* **Learning Rate Schedules (학습률 스케줄):** 학습이 진행됨에 따라 **학습률을 점진적으로 줄여나가는 방식**입니다. 초기에는 큰 학습률로 빠르게 최적해 근처로 이동하고, 최적해에 가까워질수록 작은 학습률로 정밀하게 조정하는 데 사용됩니다.

**4. 중요성:**

* **60년 이상 사용된 머신러닝의 핵심 알고리즘**이며, 현대 딥러닝의 발전에 필수적인 토대를 제공했습니다.
* **ChatGPT와 같은 거대 언어 모델, 개인화된 추천 시스템 등** 현대 AI 기술의 핵심인 다양한 모델 학습에 광범위하게 활용되고 있습니다.

**5. 요약:** 
* 경사 하강법은 모델의 예측 오류를 줄이기 위해 오류 함수의 기울기를 계산하고, 이 기울기의 반대 방향으로 모델의 파라미터를 조금씩 반복적으로 조정하여 **최적의 해를 찾아나가는 기본적인 머신러닝 최적화 알고리즘**입니다. 학습률, 미니 배치, 모멘텀 등 다양한 기법들이 경사 하강법의 효율성과 안정성을 높이는 데 기여


## 11. 대부분의 사람들이 잘못 이해하는 머신 러닝에 대한 30가지 사실
- 출처: [30 Machine Learning Facts Most People Get Wrong]()

### 11.1 사람들이 오해하고 있는 30가지 

**1. AI ≠ 머신러닝:**  
*   AI는 넓은 개념, 머신러닝은 AI의 하위 분야.  
    - AI는 로봇, 자연어 처리, 전문가 시스템 등 지능을 모방하는 모든 기술을 포괄하며, 머신러닝은 그중 데이터 기반 학습에 초점을 맞춘다. 예를 들어, 체스 AI는 규칙 기반일 수 있지만, 이미지 인식은 머신러닝에 의존한다.  
*   AI는 지능적인 정보 처리 시스템, 머신러닝은 데이터 학습에 특화.  
    - AI는 인간처럼 사고하거나 문제를 해결하려는 시도를 포함하지만, 머신러닝은 통계적 패턴을 찾아 예측하거나 분류하는 데 강점이 있다.

**2. 딥러닝 > 전통 ML? NO:**  
*   딥러닝은 계층적 표현 학습에 강점, 구조화된 데이터나 작은 데이터셋에는 취약.  
    - 이미지나 음성처럼 복잡한 비정형 데이터에서 딥러닝이 빛을 발하지만, 고객 데이터 테이블 같은 구조화된 데이터에서는 랜덤 포레스트 같은 전통 ML이 더 빠르고 정확할 수 있다.  
*   때로는 선형 회귀가 더 효과적일 수 있음.  
    - 예를 들어, 집값 예측처럼 변수 간 선형 관계가 뚜렷할 때는 간단한 선형 회귀가 복잡한 신경망보다 낫다.

**3. 인공신경망 ≠ 인간 두뇌:**  
*   인공신경망은 수학적 함수들의 조합.  
    - 뉴런을 모방한다고 하지만, 실제로는 활성화 함수와 행렬 연산으로 작동하며 감정이나 의식 같은 인간적 요소는 없다.  
*   인간 신경세포와는 다른 메커니즘.  
    - 인간 뇌는 화학적 신호와 전기 신호로 학습하며, 환경에 적응하는 방식이 훨씬 유연하고 복잡하다.

**4. 지도 학습 ≠ 인간 감독:**  
*   지도 학습은 정답(label)이 있는 데이터로 학습.  
    - 예를 들어, 고양이 사진에 “고양이”라는 라벨을 붙여 모델이 이를 학습하지만, 사람이 실시간으로 개입하지는 않는다.  
*   모델 학습 과정을 지켜보는 것이 아님.  
    - 학습은 자동화된 알고리즘이 주도하며, 인간은 데이터 준비와 결과 평가에만 관여한다.

**5. 파라미터 ≠ 하이퍼파라미터:**  
*   파라미터: 모델이 학습하는 값 (학생이 알아내는 답).  
    - 신경망의 가중치나 회귀 모델의 기울기처럼 데이터에서 도출된다.  
*   하이퍼파라미터: 엔지니어가 설정하는 값 (교사가 설계하는 교육 과정).  
    - 학습률, 레이어 수, 배치 크기 등은 모델 학습 전에 사람이 직접 조정하며, 결과에 큰 영향을 미친다.

**6. 머신러닝 ≠ 기계의 이해:**  
*   머신러닝은 패턴 매칭, 최적화 과정.  
    - 모델은 데이터를 보고 숫자 패턴을 찾아 손실 함수를 줄이는 데 집중한다.  
*   모델은 이해하는 것이 아니라 숫자를 최소화하는 것.  
    - 예를 들어, 스팸 메일 필터는 단어 빈도를 계산해 분류하지만, 메일의 의미를 “이해”하지는 않는다.

**7. 데이터는 많을수록 좋다? NO:**  
*   작지만 잘 정제된 데이터셋이 더 효과적일 수 있음.  
    - 잡음이 많은 대규모 데이터보다 신중히 큐레이션된 소규모 데이터가 모델 성능을 높일 수 있다.  
*   데이터 크기보다 특징의 질과 데이터의 깨끗함이 중요.  
    - 예를 들어, 의료 데이터에서 잘못된 기록이 많으면 모델이 오히려 잘못된 패턴을 학습한다.

**8. 데이터 증강은 항상 옳다? NO:**  
*   데이터 증강은 편향을 유발할 수 있음.  
    - 이미지 회전으로 데이터를 늘리면 좋지만, 숫자 데이터에 무작위 노이즈를 추가하면 오히려 혼란을 줄 수 있다.  
*   의료 영상, 금융 데이터 등 도메인에 따라 부적절한 증강 방식 존재.  
    - 예를 들어, X-ray 이미지에 과도한 변형을 가하면 질병 특징이 왜곡될 수 있다.

**9. 모델 복잡도 ∝ 모델 크기? NO:**  
*   파라미터 수가 많다고 복잡한 관계를 표현하는 것은 아님.  
    - 파라미터가 많아도 단순 선형 패턴만 학습할 수 있다.  
*   파라미터를 어떻게 활용하는지가 중요.  
    - 효율적인 구조 설계가 더 복잡한 문제를 풀어내는 열쇠다.

**10. 특징 엔지니어링은 딥러닝에 불필요? NO:**  
*   딥러닝은 자동 특징 추출 가능, 하지만 하이퍼파라미터 튜닝 필요.  
    - 이미지에서 엣지를 자동으로 찾지만, 최적의 학습을 위해 여전히 조정이 필수다.  
*   전통 ML은 잘 설계된 특징으로 딥러닝보다 뛰어난 성능 가능.  
    - 예를 들어, 금융 예측에서 수작업으로 만든 “이동 평균” 특징이 딥러닝보다 나을 수 있다.

**11. 100% 정확도 = 좋은 모델? NO:**  
*   과적합(Overfitting)의 가능성.  
    - 모델이 학습 데이터에만 너무 맞춰져 새로운 데이터에서 실패할 수 있다.  
*   모델이 학습 데이터를 암기하는 것과 같음.  
    - 시험 문제와 답을 외운 학생이 새로운 문제를 못 푸는 것과 비슷하다.

**12. 균형 데이터셋 = 좋은 데이터셋? NO:**  
*   실제 세상은 불균형한 경우가 많음.  
    - 사기 거래는 전체의 1% 미만일 수 있다.  
*   현실 세계의 분포를 반영하는 것이 중요.  
    - 균형을 강제로 맞추면 모델이 현실에서 작동하지 않을 수 있다.

**13. 결측값 = 나쁜 데이터? NO:**  
*   결측값 자체가 정보가 될 수 있음.  
    - 설문조사에서 “응답 없음”이 특정 태도를 나타낼 수 있다.  
*   결측이 발생한 이유를 분석하는 것이 중요.  
    - 결측 패턴을 이해하면 모델이 더 나은 결정을 내릴 수 있다.

**14. 이상치 = 오류? NO:**  
*   이상치가 중요한 정보를 담고 있을 수 있음.  
    - 예를 들어, 은행 거래에서 큰 금액은 사기일 가능성이 높다.  
*   사기 탐지, 과학적 발견 등에 활용 가능.  
    - 이상치를 제거하면 중요한 신호를 놓칠 수 있다.

**15. 레이어가 많을수록 좋다? NO:**  
*   GPU 시간 낭비일 수 있음.  
    - 불필요한 레이어는 계산 비용만 늘린다.  
*   적절한 모델 용량과 문제 복잡도 사이의 균형이 중요.  
    - 간단한 분류 문제에 100개 레이어는 과잉이다.

**16. 교차 검증은 필수? NO:**  
*   시계열 데이터 등 다른 검증 전략이 더 적합한 경우 존재.  
    - 주식 데이터는 시간 순서를 고려해야 하므로 교차 검증이 부적절하다.  
*   데이터 특성에 맞는 검증 방식 선택.  
    - 데이터의 시간적, 공간적 구조를 고려해야 한다.

**17. 정확도 = 최고의 지표? NO:**  
*   문제의 요구 사항에 맞는 지표를 사용해야 함.  
    - 암 진단에서 놓친 환자가 많으면 정확도는 높아도 의미가 없다.  
*   희귀 질병 진단 등 불균형 데이터셋에서는 정확도가 의미 없을 수 있음.  
    - 재현율이나 F1 점수가 더 유용할 수 있다.

**18. 모델 해석력은 성능과 trade-off 관계? NO:**  
*   모델 해석력을 높이는 도구와 기술 존재.  
    - SHAP, LIME 같은 방법으로 모델 결정을 설명할 수 있다.  
*   정확도와 해석력 모두 확보 가능.  
    - 의료 분야처럼 해석이 필수적인 경우 두 가지를 모두 만족시킬 수 있다.

**19. 높은 정밀도 > 높은 재현율? NO:**  
*   모델의 실수에 대한 현실 세계의 결과에 따라 선택.  
    - 정밀도는 오탐을 줄이고, 재현율은 미탐을 줄인다.  
*   오진의 위험 vs. 놓치는 환자의 위험.  
    - 암 진단에서는 재현율이, 스팸 필터에서는 정밀도가 더 중요할 수 있다.

**20. 앙상블 모델 > 단일 모델? NO:**  
*   모델들이 같은 실수를 반복하면 효과 X.  
    - 비슷한 약점을 가진 모델을 합쳐도 개선이 없다.  
*   다양한 종류의 오류를 범하는 모델들을 앙상블해야 효과적.  
    - 예를 들어, 트리 모델과 신경망을 결합하면 더 robust해진다.

**21. 모델의 높은 확신도 = 신뢰도? NO:**  
*   모델은 확신에 차서 틀릴 수 있음.  
    - 딥러닝은 잘못된 예측에도 높은 확률을 부여할 수 있다.  
*   특히 딥러닝 모델은 과신 경향이 있음.  
    - 이를 보정하기 위해 불확실성 추정 기법이 필요하다.

**22. 머신러닝 모델은 항상 재학습해야 한다? NO:**  
*   데이터 분포가 변하지 않으면 안정성이 더 중요.  
    - 예를 들어, 물리 법칙 기반 모델은 재학습이 필요 없다.  
*   불필요한 위험을 초래할 수 있음.  
    - 잦은 재학습은 모델의 일관성을 해칠 수 있다.

**23. 클라우드 배포 > 엣지 배포? NO:**  
*   자율 주행 등 실시간성이 중요한 경우에는 엣지 배포가 필수.  
    - 네트워크 지연 없이 즉각적인 처리가 필요하다.  
*   상황에 따라 효율성과 필요성이 달라짐.  
    - 비용과 보안도 배포 방식을 결정하는 요소다.

**24. AutoML > 수동 튜닝? NO:**  
*   AutoML은 서브 최적 모델을 더 빠르게 구축하는 과정.  
    - 일반적인 문제에 적합하지만, 특수한 경우 최적화가 부족할 수 있다.  
*   경험 많은 데이터 과학자는 도메인 특정 최적화를 포착할 수 있음.  
    - 예를 들어, 의료 데이터에서 전문가가 만든 특징이 더 유리하다.

**25. 전이 학습은 항상 유익하다? NO:**  
*   한 도메인에서 학습된 특징이 다른 도메인에 의미 있게 전달되지 않을 수 있음.  
    - 개와 고양이 분류 모델을 새 인식에 쓰면 혼란이 생길 수 있다.  
*   때로는 성능 저하를 야기.  
    - 도메인 차이가 크면 처음부터 학습하는 게 나을 수 있다.

**26. ML 프로젝트 실패 원인 = 기술적 문제? NO:**  
*   조직 및 커뮤니케이션 문제인 경우가 많음.  
    - 팀 간 목표 불일치나 데이터 접근 문제로 실패할 수 있다.  
*   이해 관계자 간의 소통, 문제 정의의 중요성.  
    - 기술이 좋아도 비즈니스 요구를 반영하지 못하면 무용지물이다.

**27. 신경망은 블랙박스? NO:**  
*   신경망 내부를 분석하는 도구와 기술이 개발됨.  
    - Grad-CAM으로 이미지에서 모델이 주목한 부분을 시각화할 수 있다.  
*   어떤 레이어가 어떤 특징을 감지하는지 확인 가능.  
    - 예를 들어, 첫 번째 레이어가 엣지를, 깊은 레이어가 얼굴을 인식한다.

**28. ML에서 데이터 프라이버시는 항상 손상된다? NO:**  
*   연합 학습, 차분 프라이버시 등 개인 정보 보호 기술 존재.  
    - 연합 학습은 병원 데이터를 중앙 서버로 보내지 않고도 모델을 훈련시킨다.  
*   개별 데이터에 직접 접근하지 않고 모델 학습 가능.  
    - 데이터 프라이버시를 지키면서도 성능을 유지할 수 있다.

**29. 모델 편향은 항상 나쁘다? NO:**  
*   유용한 귀납적 편향(inductive bias)이 존재.  
    - CNN은 이미지의 공간 구조를 가정하며 학습 속도를 높인다.  
*   모델의 합리적인 가정 (사전 지식)은 학습에 필수적.  
    - 적절한 편향은 과적합을 줄이고 일반화를 돕는다.

**30. 머신러닝은 정해진 규칙을 따르는 것? NO:**  
*   각 문제의 고유한 뉘앙스를 이해하는 것이 중요.  
    - 동일한 알고리�이라도 도메인마다 다르게 적용된다.  
*   비판적 사고 능력과 상황 판단력이 핵심.  
    - 공식에만 의존하면 창의적 문제 해결이 불가능하다.



